---
title: Polars, une alternative fra√Æche √† Pandas
subtitle: Winter is coming

# Summary for listings and search engines
description: |
  Polars, une alternative moderne et fluide √† `Pandas`

# Date published
date: '2023-02-10T00:00:00Z'

# Date updated
image: featured.jpg

authors:
  - Romain Tailhurat
  - Lino Galiana

categories:
  - Python
  - Pandas
  - Polars
  - Data wrangling
---


Le concept de **[_dataframe_](https://www.databricks.com/glossary/what-are-dataframes)** est central pour le _data scientist_ qui manipule des donn√©es tabulaires.
En `Python`, [`Pandas`](https://pandas.pydata.org/) est la solution de loin la plus populaire. En moyenne, le _package_ est t√©l√©charg√©
4 millions de fois par semaine, depuis des ann√©es. 

Un petit nouveau apporte un vent de fra√Æcheur dans le domaine : [`Polars`](https://www.pola.rs/).

Ses atouts ? D'excellentes performances et une expressibilit√© qui le rapproche d'un [`dplyr`](https://dplyr.tidyverse.org/).

Ce post de blog revient sur les principaux atouts de `Polars`, sans vouloir √™tre exhaustif. Un _notebook_ illustrant les principales
fonctionnalit√©s du package vise √† le compl√©ter : 

<a href="https://datalab.sspcloud.fr/launcher/ide/jupyter-python?autoLaunch=true&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Fromaintailhurat%2Fssphub%2Fblog%2Fpolars%2Fcontent%2Fnotebooks%2Finit.sh%C2%BB&init.personalInitArgs=%C2%ABpolars-tuto%C2%BB&onyxia.friendlyName=%C2%ABTutoriel%20Polars%C2%BB" target="_blank" rel="noopener"><img src="https://img.shields.io/badge/SSPcloud-Tester%20via%20SSP--cloud-informational&amp;color=yellow?logo=Python" alt="Onyxia"></a>
<a href="http://colab.research.google.com/github/inseefrlab/ssphub/blob/main/content/notebooks/polars-tuto.ipynb" target="_blank" rel="noopener"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a>




# Les secrets de la performance

Les _benchmarks_ disponibles [sont clairs](https://h2oai.github.io/db-benchmark/) : `Polars` est
un ours qui court vite !

Le benchmark suivant, [effectu√© par H2O](https://h2oai.github.io/db-benchmark/), propose
un comparatif de la vitesse des principaux frameworks de manipulation de donn√©es
pour effectuer une agr√©gation par groupe avec un jeu de donn√©es de 50GB:

![Benchmark H2O](polars-benchmark-short.png)

`Polars` devance des solutions connues pour leur efficacit√© sur ce type d'op√©rations, 
comme le package `R` `data.table`. L'utilisateur habituel de `Pandas`
ne pourrait m√™me pas traiter ces donn√©es, qui exc√®dent les capacit√©s computationnelles
de sa machine.

## L'√©valuation _lazy_

Plusieurs √©l√©ments expliquent cette rapidit√©.

En premier lieu, `Polars` est con√ßu pour optimiser les requ√™tes :
gr√¢ce au mode _lazy_ (_"paresseux"_),
on laisse la possibilit√© au moteur d'analyser ce qu'on souhaite faire
pour proposer une ex√©cution optimale (pour la lecture comme pour la transformation des jeux de donn√©es).
La _lazy evaluation_ est une m√©thode assez commune pour am√©liorer la vitesse
des traitements et est utilis√©e, entre autres, par `Spark`.

Du fait de
la _lazy evaluation_ il est ainsi possible, par exemple,
si un filtre sur les lignes arrive 
tardivement, de le remonter dans l'ordre des op√©rations effectu√©es par `Python`
afin que
les op√©rations ult√©rieures ne soient effectu√©es que sur
l'ensemble optimal de donn√©es.
Ces optimisations sont d√©taill√©es dans la [documentation officielle](https://pola-rs.github.io/polars-book/user-guide/optimizations/intro.html). 

## Lecture optimis√©e des fichiers

L'utilisateur `Pandas` est habitu√© √† lire du CSV avec `pd.read_csv`. 
Avec `Polars`, il existe deux mani√®res, tr√®s ressemblantes
de le faire.

```python
import polars as pl

# Cr√©ation d'une requ√™te
q = (
    pl.scan_csv("iris.csv") # Lecture lazy
    .filter(pl.col("sepal_length") > 5)
    .groupby("species")
    .agg(pl.all().sum())
)

# Ex√©cution de la requ√™te
df = q.collect()
```

Avec cette syntaxe, les connaisseurs de `Pyspark` retrouveront facilement leurs petits (ours üêª). 

On peut toujours lire de mani√®re plus directe
(en mode _eager_, _"impatient"_) en utilisant la fonction `read_csv`,
et ensuite appliquer des transformations optimisables en glissant habilement `lazy` :

```python
df = pl.read_csv("iris.csv")

df_res = df.lazy() # ‚Üê  ici :)
  .filter(pl.col("sepal_length") > 5)
  .groupby("species")
  .agg(pl.all().sum())
  .collect()
```

`Polars` fonctionne √©galement tr√®s bien avec le format `Parquet`, comme illustr√© dans
le _notebook_ qui accompagne ce _post_.


## Parall√©lisation

`Polars` parall√©lise les traitements d√®s que cela est possible, notamment dans le cas d'agr√©gation.
Chaque coeur se charge d'une partie de l'agr√©gation et envoie des donn√©es plus l√©g√®res √† `Python`
qui va finaliser l'agr√©gation.

![Parall√©lisation](polars-split-parallel-apply-combine.svg)

_Illustration du principe de la parall√©lisation_

Sur les syst√®mes proposant de nombreux coeurs, cela peut faire gagner beaucoup de temps.

## Des couches basses √† la pointe

Enfin, le choix d'utiliser √† la fois le format de repr√©sentation en m√©moire [Arrow](https://arrow.apache.org/) et le langage [Rust](https://www.rust-lang.org/fr) pour le coeur de la biblioth√®que n'est pas √©tranger √† cette performance.

## Calculs _out of memory_

`Polars` travaille vite mais pr√©sente aussi l'avantage
de lire naturellement des jeux de donn√©es hors des limites de la m√©moire de l'ordinateur gr√¢ce √† [sa capacit√© de lire en flux](https://www.youtube.com/watch?v=3-C0Afs5TXQ) (m√©thode qu'on appelle le _streaming_).


```python
# La m√™me requ√™te que tout √† l'heure va lire le fichier "en flux"
df = q.collect(streaming=True)
```

De plus, `Polars` lit nativement les fichiers `Parquet` qui par ses propri√©t√©s
permet d'aller beaucoup plus vite que le CSV !

# Une API fluide

C'est un reproche r√©guli√®rement fait √† `Pandas` :
la syntaxe de manipulations des donn√©es est parfois complexe ou peu lisible, et les choix d'√©criture ne sont pas transparents du point de vue des performances.

L'API propos√©e par Polars est √† la fois expressive et transparente.
Voici un exemple d'exploitation de la BPE, issu du _notebook_ accompagnant 
ce _post_ :

```python
df.lazy()
  .filter(
    pl.col("TYPEQU") == "B316"
  )
  .groupby("DEP")
  .agg(
    pl.count().alias("NB_STATION_SERVICE")
  )
  .collect()
```

On retrouve une s√©mantique d'op√©rations de haut niveau qui s'encha√Ænent √† la mani√®re de [ce que l'on peut faire en `dplyr`](https://www.book.utilitr.org/03_fiches_thematiques/fiche_tidyverse#comment-utiliser-lop%C3%A9rateur-pipe-avec-le-tidyverse).

# Les autres concurrents

`Pandas` et `Polars` ne sont pas seuls dans le grand zoo de la manipulation de donn√©es en Python : des solutions comme [Vaex](https://github.com/vaexio/vaex) ou [Dask](https://github.com/dask/dask) ont des arguments √†
faire valoir. 
`DuckDB`, un autre _framework_ de manipulation de donn√©es, s'int√®gre quand √† lui tr√®s bien
avec  `Polars` dans la m√©nagerie.

![](dalle_polar_duck.png){width=40% fig-align="center"}

_Le duo DuckDB-Polars illustr√© par Dall-E-2_

# Ressources suppl√©mentaires

- [_Awesome Polars_ par Damien Dotta (INSEE)](https://github.com/ddotta/awesome-polars)
- [Polars pour R](https://rpolars.github.io/)
- [rhosignal.com/tags/polars/](https://www.rhosignal.com/tags/polars/)
- [kevinheavey.github.io/modern-polars/](https://kevinheavey.github.io/modern-polars/)

Le _notebook_ accompagnant ce _post_:

<a href="https://datalab.sspcloud.fr/launcher/ide/jupyter-python?autoLaunch=false&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Fromaintailhurat%2Fssphub%2Fblog%2Fpolars%2Fcontent%2Fnotebooks%2Finit.sh%C2%BB&init.personalInitArgs=%C2%ABpolars-tuto%C2%BB&onyxia.friendlyName=%C2%ABTutoriel%20Polars%C2%BB" target="_blank" rel="noopener"><img src="https://img.shields.io/badge/SSPcloud-Tester%20via%20SSP--cloud-informational&amp;color=yellow?logo=Python" alt="Onyxia"></a>
<a href="http://colab.research.google.com/github/inseefrlab/ssphub/blob/main/content/notebooks/polars-tuto.ipynb" target="_blank" rel="noopener"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a>
