---
title: "Onyxia: l'infrastructure cloud mère des dragons"
subtitle: Une infrastructure de data science avec les technologies à la pointe
toc: true
summary: |
  TO BE COMPLETED
# Link this post with a project
projects: [onyxia]

# Date published
date: '2023-01-10T00:00:00Z'

# Date updated
lastmod: '2023-01-10T00:00:00Z'

# Is this an unpublished draft?
draft: false

# Show this page in the Featured widget?
featured: true

# Featured image
# Place an image named `featured.jpg/png` in this page's folder and customize its options here.
#image:
#  focal_point: ''
#  placement: 2
#  preview_only: false

authors:
  - linogaliana

tags:
  - onyxia
  - sspcloud

categories:
  - Insee

bibliography: references.bib
---


`Onyxia` est un logiciel _open source_ développé par l’Insee
([disponible sur `Github` <i class="fa-brands fa-github"></i>](https://github.com/InseeFrLab/onyxia-web))
permettant de fournir un environnement de traitement de données à l’état de l’art.
Principalement conçu pour permettre le travail interactif des data scientists,
l’expérience fournie avec `Onyxia`
favorise également la reproductibilité des travaux et leur mise en production.

Le logiciel `Onyxia` est installé par des organisations souhaitant créer un _datalab_,
c'est-à-dire une plateforme interactive de traitement de données.
Ces organisations ont toutes le point commun de vouloir construire une plateforme qui embrasse
les technologies _cloud_ que sont la conteneurisation et le stockage objet tout en mettant à
disposition celles-ci dans un environnement _user-friendly_ où l'interconnexion entre ces
différentes briques est gérée de manière cohérente.
Les technologies _cloud native_ étant devenues indispensables dans l’écosystème de la donnée, 
par la meilleure gestion des ressources et la capacité à créer un
environnement parfaitement reproductible pour une mise en production accélérée, ont beaucoup
à apporter à l'administration française.

Ce _post_ de blog a pour objectif de présenter la raison d'être d'`Onyxia`,
sa génèse et les solutions qu'apporte cette infrastructure à des irritants
classiques des projets novateurs de data science. 

## Contexte

L'écosystème de la data science est en mouvement accéléré depuis 10 ans
et le rôle du _data scientist_ dans les organisations valorisant de la donnée
a évolué [@davenport2022data]. 
Les data scientists modernes sont amenés à utiliser de plus en plus
de langages et doivent être capables de maîtriser plusieurs
architectures informatiques. La frontière est ainsi moins nette
que par le passé entre
statisticiens et informaticiens. 
De plus, les innovations récentes dans le monde du
développement logiciel, notamment 
l'adoption massive de l'approche `DevOps` -
approche qui consiste à automatiser la production de livrables dès la conception
du prototype -
a également fait évoluer les pratiques des data scientists.

Ce besoin de ressources informatiques croissantes, 
de flexibilité dans le prototypage de solutions informatiques et l'évolution des
pratiques
consistant à mettre à disposition en continu des livrables ont eu des implications
importantes sur les architectures informatiques dominantes dans l'écosystème de la 
donnée.
Pour répondre au besoin croissant de puissance de traitement, les serveurs
partagés, organisés sous forme de clusters, se sont développés dans de 
nombreuses organisations.
Après avoir connue son heure de gloire au début des années 2010, l'infrastructure
[`HDFS` (_Hadoop Distributed File System_)](https://openclassrooms.com/fr/courses/4467481-creez-votre-data-lake/4509426-decouvrez-le-systeme-de-fichiers-distribue-hdfs), 
qui reposait sur des _clusters_ où les données et la puissance de traitement étaient
distribués et collocalisés, a laissé place à des infrastructures
plus scalables, basées sur l'approche de la conteneurisation. 

## De HDFS aux conteneurs à Kubernetes


Cette partie plus technique développe des éléments pour comprendre
le succès récent des infrastructures conteuneurisées. 
Elle pourra intéresser le lecteur curieux sur les fondements
des infrastructures _cloud_ modernes mais n'est pas nécessaire
à la compréhension générale de l'article.

Voici un résumé de ces éléments:

> La conteuneurisation, qui repose
> sur l'idée que les serveurs de stockage de la donnée peuvent être dissociés de ceux
> effectuant les traitements, sert de fondement aux principales plateformes _cloud_ fournissant 
> des services à la demande.
> 
> Ce nouveau paradigme part de deux constats. Le premier
> est que les
> échanges de données entre les noeuds d'un serveur sont aujourd'hui peu coûteux.
> Avec des flux réseaux suffisants et une technologie
performante, 
> il est donc possible d'échanger des grands volumes de données au sein d'une infrastructure.
> Le deuxième constat est que la maintenance d'une infrastructure conteuneurisée est
> plus légère que celle d'une infrastructure basée sur des machines virtuelles ou sur
> la collocalisation des données et des traitements comme HDFS. 
> 
> Les données étant stockées sur des serveurs différents de ceux exécutant les traitements,
> l'accès à celles-ci fait à travers des API qui 
> permettent de traiter le système de stockage distant comme un système de fichiers
> classiques. Le SSP Cloud a adopté une implémentation _open source_ du système de stockage
> S3 appelée [`MinIO`](https://min.io/). En ce qui concerne le traitement des données, le fait
> d'utiliser un système de conteneurs, c'est-à-dire une configuration logicielle portable minimaliste
> prête à l'emploi (par opposition aux machines virtuelles qui impliquent un système d'exploitation complet), 
> offre une grande liberté sur le choix des logiciels de traitement. De nombreuses technologies 
> _open source_ devenues standards dans le monde de la _data science_ (Jupyter, RStudio, ElasticSearch...) 
> existent déjà sous cette forme et peuvent ainsi être adoptées dans une telle infrastructure. La mise en 
> musique de toutes ces petites boites auto-suffisantes, notamment l'optimisation des ressources concurrentes
> sur un serveur, est permise par la technologie d'orchestration [`Kubernetes`](https://kubernetes.io/fr/).

```{python}
#| output: asis
#| echo: false
with open('onyxia_logic.svg') as f:
    s = f.read()
print(s)
```

<br>

```{=markdown}
{{{< spoiler text="Plus de détails pour comprendre le changement de paradigme vers la conteuneurisation" >}}}


Les infrastructures _big data_ reposent sur le principe du _cluster_ (grappe) informatique.
Des serveurs sont connectés entre eux, ce qui forme de manière imagée une grappe. 
Cette interconnexion de plusieurs serveurs entre eux peut se faire au niveau :

- du stockage: les données volumineuses ne sont pas stockées sur un seul serveur mais au contraire réparties ;
- du traitement: les calculs sont effectués par blocs sur plusieurs serveurs et le résultat
de ceux-ci est ensuite transmis à un serveur maître. 

Le système _Hadoop Distributed File System_ a été pensé pour tirer parti
de l'algorithme de traitement
parallélisé [`MapReduce`](https://fr.wikipedia.org/wiki/MapReduce) proposé en 2004
par `Google`. Les fichiers
volumineux sont fractionnés et répartis sur plusieurs serveurs.

![](https://i0.wp.com/datascientest.com/wp-content/uploads/2021/04/illu_schema_mapreduce-04.png?w=1024&ssl=1)

Source: Fonctionnement d'une architecture `MapReduce` [Datascientest](https://datascientest.com/mapreduce)

La spécificité de l'architecture HDFS est que non seulement le stockage est
distribué mais aussi la puissance de traitement associée également.  
On parle à
ce propos de collocalisation: les traitements ont lieu sur les mêmes serveurs
que ceux où sont stockés les données. Cela permet
de réduire les mouvements de données (_shuffle_ dans l'image ci-dessus) qui 
sont coûteux en termes de performance.
Cette collocalisation a permis au 
système HDFS de devenir, au début de la décennie 20210,
le paradigme dominant. En
tirant parti de la parallélisation
permise par des langages très efficaces comme `Spark` tout en limitant les
échanges réseaux pouvant faire perdre en performance, cette 
architecture a attiré au delà de l'écosystème du _big data_. 

Le système HDFS présente néanmoins certaines limites qui expliquent sa
perte de succès avec l'émergence d'un nouveau paradigme plus flexible.

En premier lieu,
ce système nécessite beaucoup de ressources du fait de son _design_. Comme
les traitements sont lourds et partagés pour des usages concurrents, 
les noeuds constituant le _cluster_ peuvent subir des arrêts à cause
de surcharge des ressources. 
Pour tenir
compte de la nature instable de cette infrastructure _big data_,
les fichiers 
sont dupliqués afin qu'une erreur sur le
serveur (par exemple à cause de traitements trop gourmands)
générant un arrêt du noeud
permette tout de même de sécuriser les traitements sur l'ensemble
des données et éviter la perte de données ou des traitements
sur un ensemble partiel des données. L'implication est que les données, 
déjà volumineuses, sont dupliquées plusieurs fois ce qui 
implique des architectures assez monumentales. Si la duplication
de la donnée n'est
pas en soi choquante afin d'éviter la perte de données,
cela a un effet 
pervers dans un système de collocalisation. A chaque ajout de noeuds
pour le stockage de données, il est également nécessaire d'ajouter 
des ressources pour les traiter. Il est donc compliqué de décorréler 
l'ajout de ressources de stockage et de traitement. Cette absence
de flexibilité est pénalisante dans un monde où les données sont mises
à jour fréquemment et où les technologies de traitement, 
donc les besoins associés, évoluent rapidement. Les infrastructures HDFS
sont donc lourdes à faire évoluer, que ce soit pour ajouter des ressources
ou faire évoluer les distributions logicielles présentes dessus.

Le deuxième facteur qui a favorisé un changement de paradigme est l'amélioration
des échanges réseaux. Il n'est plus aussi coûteux que par le passé de transférer
des volumes importants de données au sein d'une infrastructure. Cela facilite
la décorrélation entre environnement de stockage et de traitement.

Cette séparation
des environnements de stockage et de traitement 
permet alors d'adopter pour chacun les technologies
les plus performantes. Dans le domaine du stockage, celle qui 
a rencontré le plus de succès est
le système de stockage [`S3`](https://aws.amazon.com/fr/s3/) développé
par Amazon. L'implémentation _open source_ du système S3
est [`MinIO`](https://min.io/), utilisée
par le SSP Cloud.

Dans le domaine du traitement, la technologie la plus performante
dépend de la nature de la tâche réalisée.
Selon qu'on désire effectuer de la recherche
textuelle, des visualisations de données
ou de l'analyse d'image, on ne va pas vouloir utiliser
la même technologie. Pour mettre à disposition des logiciels
sur un serveur, il existe principalement deux approches concurrentes.

La première repose sur le principe des machines virtuelles. 
Cette approche n'est pas nouvelle et de nombreuses organisations ont
proposé ou proposent encore ce type d'infrastructures pour des serveurs
collectifs de traitement. Cette approche est néanmoins lourde: elle nécessite
un système d'exploitation complet pour ensuite adapter la configuration pour
chaque logiciel à installer. Plusieurs logiciels coexistent
donc dans ce système
d'exploitation même si un seul, par exemple, `Python`, est nécessaire. 
Les machines virtuelles sont des infrastructures assez polluantes puisque pour
faire fonctionner un système d'exploitation dans son ensemble, il
est nécessaire de mobiliser des ressources plus importantes que celles seulement
nécessaires aux traitements. 
De plus, la configuration d'un système d'exploitation, et notamment, la gestion
de la dépendance de multiples logiciels à des configurations systèmes qui
peuvent ne pas correspondre, n'est pas triviale. Il est donc lourd de faire
évoluer une infrastructure reposant sur des machines virtuelles. Dans un
écosystème mouvant comme celui de la _data science_, où une partie importante
du travail de prototypage consiste à tester plusieurs technologies 
pour déterminer celle s'intégrant le mieux dans un processus de traitement
de données, l'absence de flexibilité d'une infrastructure reposant
sur le principe des machines virtuelles est pénalisante. 

Le système de la conteneurisation a justement été pensé
pour cela: plutôt qu'installer des librairies au niveau du système, pour une fraction 
d'utilisateurs limitée, il est plus intéressant de créer des environnements complets
qui vont exister de manière conjointe. Chaque _framework_ va être construit comme
un conteneur autosuffisant avec un système d'exploitation minime et un nombre
minimal de couches de configurations supplémentaires. Un _framework_ est livré
sous la forme d'une
image [`Docker`](https://fr.wikipedia.org/wiki/Docker_(logiciel)), une technologie
qui permet d'empâqueter un logiciel et ses dépendances sous la forme de boites
minimalistes et les mettre à disposition facilement pour une réutilisation. 
Il existe par exemple des images `Docker` pour pouvoir utiliser `RStudio`, `Jupyter`,
`VSCode`
dans des configurations minimalistes pour pouvoir utiliser `Python` ou `R`. 
Mais les images `Docker` ne se réduisent pas à la mise à disposition
d'environnements de développement.
Une partie des technologies les plus appréciées de l'écosystème de la
data science sont également livrées sous forme d'images `Docker`. Par
exemple, le moteur de recherche `ElasticSearch`, très utilisé pour
la recherche textuelle, peut être empâqueté dans une
image `Docker`. Le logiciel Onyxia propose dans un catalogue vivant
un certain nombre
de logiciels très utiles pour les _data scientists_. 
Les nombreuses images `Docker` servant à créer des services 
pour les _data scientists_ sont disponibles en _open source_ 
sur [`Github`](https://github.com/InseeFrLab/images-datascience)

Pour organiser la coexistence sur un serveur 
de multiples utilisateurs de services gourmands en ressource, 
la solution [`Kubernetes`](https://kubernetes.io/fr/).
Entre sa création en 2014 et aujourd'hui, cette solution
d'orchestration, c'est-à-dire de gestion d'une infrastructure,
est devenue incontournable. Outre son allocation dynamique
des ressources, elle permet de transformer facilement
le livrable d'une chaine de traitement
en application disponible en continu. Ceci est
particulièrement adapté dans un contexte de
diversification
des livrables fournis par les _data scientists_:
API, application web...

{{{< /spoiler >}}}
```

## La solution Onyxia

Pour permettre aux data scientists des administrations françaises
de bénéficier de technologies _cloud_ sans être dépendant d'un
fournisseur de service privé,
l'équipe innovation de l'Insee a eu l'idée de créer un
_datalab_ basé sur la philosophie de la conteunerisation en 
mobilisant exclusivement des composants open-source. 
Ce _datalab_, né à l'Insee en 2018, a été ouvert à l'administration
publique sous la forme d'une instance https://www.sspcloud.fr/
sous la condition d'utiliser des données ouvertes. 
Depuis deux ans, cette infrastructure sert à former les élèves de l'ENSAE
dans le cadre de leur formation en _data science_. 

Début 2022, ce sont plus de 3000 agents et étudiants qui sont inscrits 
sur cette infrastructure avec, en moyenne, 300 utilisateurs
hebdomadaires. L'infrastructure de traitement propose 10 TB de RAM,
1100 CPU disponibles et 34 GPU. La capacité de stockage associée 
est de 150 TB. 

Pour les utilisations internes de données plus sensibles,
l'équipe innovation
de l'Insee a rendu disponible
le code source derrière le `SSP Cloud`
dans le cadre d'un logiciel
nommé `Onyxia` (https://www.onyxia.sh/).
Ce logiciel est pensé comme un kit qui peut être installé
sur un _cluster_ `Kubernetes`, technologie détaillée
précédemment. 


Plus précisément, Onyxia propose deux composants de valeur :

* une interface web qui agit comme la porte d’entrée du data scientist sur son datalab, lui facilitant l’accès aux technologies cloud et lui permettant de démarrer ses environnements de traitement de la donnée.
* des catalogues de logiciels : une petite vingtaine de services interactifs dont les plus utilisés sont `RStudio`, `Jupyter`, `VScode`, une quinzaine de services spécialisés dans les bases de données (`Postgres`, `ElasticSearch`...),  5 services d’automatisation (`MLflow`, `Label Studio`) et 2 services de _dataviz_ (`Redash` et `superset`)

<img src = "catalogue.svg" alt="Le catalogue Onyxia"/>




<img src = "onyxia_ecailles.svg" alt="Composantes Onyxia"/>



Onyxia est une application web qui permet aux data scientists d'accéder à un environnement de travail a l'état de l'art même sans être très pointu en informatique. Essentiellement, Onyxia transforme un repo de charts Helm en un catalogue de services configurables et configurés automatiquement.
Onyxia propose également une intégration avec S3.

Ces deux composants peuvent être adaptés en fonction des besoins internes de chaque organisation.
Il est ainsi possible de ne pas adopter l'ensemble des services ou de changer certaines des briques
de base pour l'adapter à des éléments d'infrastructure interne. Par exemple, il est possible d'adapter
la destination du service de stockage ou les configurations des environnements data science pour adapter
à des ressources. 

Tous les composants sont proposés en open source par l’Insee ce qui permet de fédérer une communauté
et est un bel exemple de mutualisation au sein de l’État et au delà. L'approche open source avec l'ensemble 
des dépôts 
sur le Github de l'équipe innovation (celui de [l'interface web](WXXX), celui des [images data science](XXXX)...).
La communauté peut proposer de nouveaux services dans le catalogue. Cette approche _bottom up_ a déjà permis 
d'adapter des services aux besoins des utilisateurs. 



Onyxia génère automatiquement un formulaire qui permet aux utilisateurs d'écraser les valeurs pas défaut des values.yaml de vos charts Helm. Onyxia vous permet également de préciser des valeurs à préremplir spécifiquement pour l'utilisateur en question. Ce mécanisme permet notamment à l'utilisateur d'être déjà authentifié à S3 et d'avoir accès à son bucket personel dès l'ouverture de Jupyter ou RStudio.


https://www.insee.fr/fr/information/6035940?sommaire=6035950



Onyxia ne cherche pas à se rendre indispensable

Nous visons à rendre les utilisateurs de la plateforme suffisamment familiers avec les technologies sous-jacentes (Kubernetes, helm, S3...) pour pouvoir s'affranchir d'Onyxia. Nous affichons les commandes exécutées sur le cluster, sur S3, sur Vault par le biais d'Onyxia.

Un explorateur de fichiers S3

Onyxia permet de glisser déposer ses jeux de données pour les uploader sur S3.

Intégration avec HashiCorp Vault

Onyxia permet de stocker les informations sensibles de type clés d'API dans Vault et de les rendre accessibles dans les services sous forme de variable.

Personnalisez l'apparence d'Onyxia

Onyxia offre de nombreuses options de personalisation. Modifiez le thème, le lien et le logo de l'entête sans avoir à toucher au code source d'Onyxia. Mais uniquement en modifiant les paramètres de votre instance. Example du customization.

Un environement de formation

Onyxia permet de générer des liens de lancement de service.
Cette fonctionalité peut être utilisée pour créer des catalogues de formations comme celui-là.

Technologiquement agnostique

Avec Onyxia vous n'investissez pas sur une stack technique en particulier sauf kubernetes et S3. Onyxia permet de rendre accessible n'importe quelle technologie cloud native et ne génére donc pas de potentielle dette technique future.

## Les plateformes basées sur Onyxia

<img src = "multiple_instances.svg" alt="Onyxia, un ensemble d'instanciations possibles"/>


L’Insee propose le SSPCloud, une plateforme ouverte à tous les agents de l’État et de nombreuses écoles et exclusivement limitée à l’exploitation de données open data. Cette stratégie d’offreur de services de traitement sur l’open data permet de montrer l’expertise de l’Insee sur les sujets data science sans prendre de risques sur la nature des projets et la complexité organisationnelle et technique des plateformes mutualisées sur données sensibles (HDH, Escale coté Drees/Dares). Afin d’illustrer les possibilités offertes par une telle plateforme, voici quelques exemples typiques :
    • la formation
    • l’organisation de hackathons
    • la mise à disposition de services innovants aux SSM (metric-osrm)
    • le travail sur données ouvertes (conception d’indicateur ou de dataviz sur des données ouvertes)
Onyxia et ses catalogues fournissent le coeur de l’offre mais l’infrastructure SSPCloud s’appuie également sur d’autres logiciels pour fournir une offre complète et cohérente :
    • le logiciel Gitlab pour offrir des dépôts de code source aux utilisateurs
    • le logiciel Minio pour offrir les espaces de stockages de données
    • kubernetes pour offrir les espaces de travail (processus / traitement)
    • Le logiciel gravitee pour offrir la possibilité aux utilisateurs de déployer des APIs et ainsi de constituer un catalogue global de toutes les APIs offertes dans le Datalab.
    • Le logiciel Atlas pour proposer des metadonnées aux utilisateurs
    • Le logiciel Grafana pour proposer aux utilisateurs un service de supervision et leur montrer leurs consommations de ressources.
L’Insee n’est désormais plus seul et fédère autour de son projet d’autres organisations. Eurostat a été la première organisation en dehors de l’Insee à choisir Onyxia fin 2021 et a présenté sa plateforme à l’international. Expertise France pour le projet DATAFID a fait le choix d’Onyxia tout comme le CASD, le GENES, Orange et BercyHub avec le projet Nubonyxia (installation d’Onyxia dans le cloud interministériel Nubo).
D’autres organisations sont plus dans une phase de POC ou d’études : l’INS norvégien, Pole Emploi, BPCE, Data4Good, l’Ineris, le ministère de l’Intérieur, le ministère de la Justice, l’Inria, EDF…




## Références