---
title: "L'IA dans l'oeil du cyclone"

description: |
  Infolettre du mois de __f√©vrier 2026__

# Date published
date: '2026-02-28'
number: 23

authors:
  - Nicolas
  - Laura

# image: minard.jpeg

categories:
  - Infolettre
---

# Bienvenue √† la **vingt troisi√®me infolettre** !

Apr√®s **Niels, Oriana et Pedro**, trois temp√™tes en 10 jours, nous revoici sous un ciel moins pluvieux.
Qu'√† cela ne tienne, je vous parie que la prochaine s'appellera [**Regina**](https://meteofrance.com/actualites-et-dossiers/comprendre-la-meteo/comment-choisit-le-nom-dune-tempete).
Bienvenue √† la nouvelle infolettre, co√©crite avec **Laura** ‚ù§Ô∏è.

# L'infographie

Dans la saison hivernale, ce mois-ci c'est le travail de l'agence italienne [The Visual Agency](https://thevisualagency.com/about/) qui a √©t√© [s√©lectionn√©](https://www.youtube.com/watch?v=yxLu5CpPUFI).
Ils ont transcrit les mots d'une conf√©rence de Marco Bernardi sur les sages et les rebelles (*i saggi e i rebelli in italiano üáÆüáπ *) en **une chaine de montagnes** dont la hauteur des sommets repr√©sente l'occurence des termes et la proximit√© entre sommets la proximit√© s√©mantique.

![*Source : The Visual Agency, Topography of a talk, [lien](https://thevisualagency.com/tva-blog-articles/topography-of-a-talk-between-vibe-coding-and-parametric-design/)*](tva_topography_talk.jpg)


Et comme c'est le mois de f√©vrier, je ne r√©siste pas √† la volont√© de mettre aussi en valeur cette
**production anim√©e des √©tapes interm√©diaires** d'une infographie faite avec ggplot lors d'un [TidyTuesday](https://github.com/gkaramanis/tidytuesday).
Depuis le premier graphique jusqu'au graphique final, c'est le rappel de tout le travail d'analyse et de mise en forme
qui est concentr√© √† la fin en une seule image.

![*Source : [Toulouse data viz](https://toulouse-dataviz.notion.site/Newsletter-Toulouse-DataViz-46-2afc08a98edb80cd9c21ee622fe9712a) et [repo TidyTuesday](https://github.com/gkaramanis/tidytuesday/tree/master/2020/2020-week15)](https://file.notion.so/f/f/adba2cb3-b809-41d0-b7a2-c0e7bfb7edbc/7ab2c090-be3f-4a5a-82d6-4f9a4b1eaf5f/gkaramanis_tour_de_france.gif?table=block&id=2c5c08a9-8edb-801e-b96f-fd56afbc37d8&spaceId=adba2cb3-b809-41d0-b7a2-c0e7bfb7edbc&expirationTimestamp=1771624800000&signature=_DQsxf79gkyZOVJzIFMqPKkAfxtWSx2qAvvogG2o9O0&downloadName=gkaramanis_tour_de_france.gif)

# Les prochaines sorties du r√©seau

## Extraction d'information de documents longs, DARES - üìÖ 18 mars 2026 14h (Insee et visio)

La Dares viendra pr√©senter leur **travail d'analyse des accords d'entreprise**, ces
documents caract√©ris√©s par leur longueur pouvant aller jusqu'√† plusieurs dizaines de page.
On y abordera les sujets et m√©thodes mises en place pour d√©tecter les th√®mes abord√©s dans les accords
et en extraire des informations pertinentes (comme le nombre de jours de t√©l√©travail hebdomadaires).

L'atelier sera √† la fois en pr√©sentiel √† l'Insee (salle 4C-358) et en visio.
Les d√©tails sont [cet √©l√©ment de calendrier](https://minio.lab.sspcloud.fr/ssphub/diffusion/website/2026-03-dares/20260318_SSPHub_DARES_accords_entreprise.ics).


## üì£ Appel √† projets - journ√©es de contribution open-source - üìÖ 16 & 17 juin 2026 - Paris

Le SSPLab organise **deux journ√©es autour de la contribution open-source les 16 et 17 juin 2026**.
Les deux jours auront lieu au *Lieu de la transformation publique √† Paris*.
Le but de ces journ√©es sera de d√©mystifier l‚Äôopen source, d'expliquer comment y contribuer, et d'encourager chacun √† soutenir les projets que nous utilisons largement en datascience.

Pour pr√©parer ces journ√©es, nous **recherchons quelques sponsors üëë**.
Le r√¥le des sponsors est de pr√©senter des projets (open-source bien s√ªr) d'int√©r√™t pour les data-scientists
auxquels on pourrait apporter une contribution lors de ces deux journ√©es.
Cela peut √™tre un package R, Python, un site ...

En tant que sponsor, vous devriez **conna√Ætre le sujet** (sans en √™tre expert ou mainteneur) et
la probl√©matique associ√©e que l'on chercherait √† r√©soudre collectivement.
Votre **r√¥le** en amont du jour J sera de pr√©parer ou identifier la ou les *issues* √† traiter
et de pr√©parer les pr√©-requis techniques (repo Git, droits d'acc√®s) pour que les contributeurs puissent
se mettre en selle rapidement avec vous le jour J.
Le jour J, vous n'aurez plus qu'√† pr√©senter le projet, la probl√©matique associ√©e et vous ins√©rer
dans le collectif dont le but sera de lancer des demandes de tirage (*pull-requests*) pour r√©pondre aux probl√©matiques soulev√©es.

Si vous avez des questions ou √™tes int√©ress√©s, n'h√©sitez pas √† nous contacter üëã par [mail](mailto:ssphub-contact@insee.fr) ou par Tchap.

# Actualit√©s

## Agents IA: petites catastrophes (et grandes cons√©quences ?)

L'usage des **agents IA** bas√©s sur des grands models de langage (LLM) a pris de l'ampleur courant 2025, notamment avec la mise √† disposition de framework et d'outils facilitant leur utilisation. Pour les plus novices d'entre nous, un agent IA est un syst√®me qui ex√©cute des t√¢ches de mani√®res autonomes, en utilisant un LLM pour comprendre et r√©pondre aux entr√©es. Il peut donc **percevoir**, **raisonner**, **d√©cider** et **agir** dans son environnement dans le but d'attendre son objectif.
On comprend donc qu'il peut exister quelques couacs dans l'utilisation de ces agents IA, c'est ce que nous allons voir dans les t√©moignages suivants:

- *quand un agent se venge pour un refus de contribution √† un projet opensource* : [**ce t√©moignage**](https://theshamblog.com/an-ai-agent-published-a-hit-piece-on-me/) nous raconte comment un agent a pu publier des propos diffamants sur l'un des *maintainers* volontaires de la librarie Python mondialement connue **Matplotlib**.

- *quand un agent vole les cl√©s d'API de son utilisateur* : [**ce t√©moignage**](https://www.reddit.com/r/ClaudeAI/comments/1r186gl/my_agent_stole_my_api_keys/?share_id=a4xNFtHEI1uNDLfrPOvxm&utm_medium=android_app&utm_name=androidcss&utm_source=share&utm_term=1) concernne cette fois un agent ayant pris quelques libert√©s pour tester une hypoth√®se : il a r√©ussi √† acc√©der √† un fichier auquel il n'avait pas acc√®s quoi qu'il en co√ªte. *Petit rappel : vos cl√© d'API üîë, c‚Äôest comme vos cl√©s d‚Äôappartement ‚Äî √† ne pas laisser tra√Æner, sinon quelqu‚Äôun risque de venir squatter‚Ä¶ et de vous laisser la facture* üëÆ

Enfin, [**ce billet de blog**](https://www.robinlinacre.com/respectful_use_of_ai/) revient sur une utilisation respectueuse de l'IA au sein des √©quipes de d√©veloppement (qui peut √™tre √©largie √† toute √©quipe bossant sur un projet commun, qu'il soit statistqiue ou informatique)

##  Outils - l'oc√©risation ou les LLM multimodaux : de nouveaux outils open source pour l'extraction de texte non structur√© üìÑ

Ces derniers mois, diff√©rents outils d'extraction d'information issus de textes non  structur√©s ont √©merg√©. On peut y retrouver:

- le framework [**EdgeQuake**](https://github.com/raphaelmansuy/edgequake), impl√©ment√© en Rust pour des performances √©lev√©es, permet de prendre en compte plus d'information sur la composition des textes que les RAG. En effet, l√† o√π les RAG se limitent √† l'analyse de la similarit√© s√©mantique, EdgeQuake va d√©composer le document en un graphe de connaissances, permettant de garder les relations structurelles entre les concepts.

- plusieurs outils d'oc√©risation - OCR pour reconnaissance optique de caract√®re ou l'exdtraction de texte issu d'image - ont √©t√© recemment mis √† disposition en open source :

  - [**chandra**](https://github.com/datalab-to/chandra?tab=Apache-2.0-1-ov-file) mis √† disposition par *datalab* l'entreprise √† l'origine du framwork [**marker-pdf**](https://github.com/datalab-to/marker?tab=readme-ov-file) ou du moteur OCR [**surya**](https://github.com/datalab-to/surya)
  - [**DeepSeek-OCR-2**](https://github.com/deepseek-ai/DeepSeek-OCR-2) s'inspire de la lecture humaine dans l'analyse du texte pour reconstruire l'ordre logique de lecture en plus de la d√©tection de caract√®res.
  - le mod√®le OCR multimodal [**GLM-OCR**](https://github.com/zai-org/GLM-OCR) analyse la structure globale du document en plus de la reconnaissance de caract√®re.

## Un (petit) d√©tour c√¥t√© R 

Parce qu'il faut des actualit√©s pour tout le monde, voici quelques news c√¥t√© R / Posit :

- Apr√®s le benchmark des meilleurs codeurs R parmi les LLM le mois dernier, [**l'infolettre Posit**](https://posit.co/blog/2026-01-16-ai-newsletter/) de janvier apporte quelques informations sur l'utilisation de LLM ou d'agents IA dans Rstudio

- Une liste des packages R utiliant les LLM est disponible [ici](https://luisdva.github.io/llmsr-book/r-pkgs.html) *bien que nous vous conseillons l'utilisation de Python si vous souhaitez travailler avec des LLM* üòâ

- Un nouvel outil [arf](https://github.com/eitsupi/arf) - *en cours de d√©veloppement, pas encore stable* - se pose en console R moderne multiplateforme, √©crit en Rust. 

- Enfin, [**ce billet de blog**](https://prodigious-trailblazer-3628.kit.com/posts/the-end-of-shiny) expose les limites d'une application **R Shiny**, en comparaison √† une "vraie" application web. Avec les nouveaux outils de *vibe coding*, est-il toujours n√©cessaire d'avoir recours au framework Rshiny, r√©put√© pour sa simplicit√© d'utilisation ? Le d√©bat est ouvert ü§î

## Formation üèãÔ∏è
Ce mois-ci, voici des **ressources int√©ressantes pour se former sur des framework IA** :

- [**DeepLearning.AI**](https://learn.deeplearning.ai/) propose des cours (gratuits apr√®s inscription) sur diff√©rents mod√®les et outils d'IA. Cette plateforme a √©t√© fond√©e par Andrew Ng, qui est aussi l'un des professeur de la plateforme ü§©

- Pour se former sur l'utilisation du framework **Pytorch**, [**learnpytorch**](https://www.learnpytorch.io/) est un excellent site, avec videos, notebooks (avec correction), pr√©sentations disponibles. Les principaux mod√®les de deepleaning sont abord√©s (dont la classification et la computer vision) et il existe m√™me un module abordant le d√©ploiement de ces mod√®les. *Tout ce dont vous avez besoin pour ma√Ætriser le package Insee [**torchTextClassifier**](https://github.com/InseeFrLab/torchTextClassifiers) comme personne* üëç 

## Fun

Vu la longueur de cette infolettre, nous vous gardons des petites p√©pites pour le mois prochain üòâ