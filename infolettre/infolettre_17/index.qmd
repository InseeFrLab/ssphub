---
title: Infolettre n¬∞17
description: |
  Infolettre, __Janvier 2024__

# Date published
date: '2024-01-20'
number: 17

image: learning.png

authors:
  - Lino Galiana

tags:
  - infolettre

categories:
  - Infolettre

filters:
  - webr

webr:
  packages: ['ggplot2']
  autoload-packages: false
---

![](learning.png){width=50% fig-align="center"}

:::{.callout-tip}

__*Vous d√©sirez int√©grer la liste de diffusion ? L'inscription se fait [ici](https://framaforms.org/integration-reseau-des-data-scientists-1676407156).*__

::: 

En ce d√©but d'ann√©e 2024, nous prenons un peu de recul sur l'ann√©e √©coul√©e et vous pr√©sentons les avanc√©es marquantes de l'ann√©e 2023 dans le domaine de la data science. Ces avanc√©es concernent l'intelligence artificielle g√©n√©rative, au c≈ìur des d√©bats m√©diatis√©s, mais aussi plusieurs d√©veloppements technologiques tr√®s utiles pour l'analyse et la diffusion de bases de donn√©es. 



## Panorama des avanc√©es de 2023 dans le domaine de la data science

### Les IA g√©n√©ratives toujours au coeur des d√©bats

Dans la continuit√©
de la sortie de `ChatGPT` en d√©cembre 2022, les IA g√©n√©ratives ont continu√© en 2023 √†
focaliser une part importante de l'attention port√©e
√† la _data science_. 
Outre la publication de GPT-4 en mars (mod√®le embarqu√© dans la version Pro de `ChatGPT`),
de nombreux grands mod√®les de langage (LLM) g√©n√©ralistes ont √©t√© publi√©s cette ann√©e:
`Llama-2` (M√©ta), `Mixtral 7B` (Mistral), `Falcon 180B` (Technology Innovation Institute), `PaLM 2` (Google)...

Ces publications ont mis en avant le caract√®re
strat√©gique de la mise √† disposition de mod√®les _open source_. La
r√©cup√©ration et la structuration de corpus massifs,
l'entra√Ænement de mod√®les int√©grant des
milliards de param√®tres et l'√©valuation _ex post_ de ceux-ci est √† la port√©e d'un
nombre restreint d'acteurs. 
La publication en _open source_ de mod√®les et de codes sources
est d√®s lors indispensable pour, entre autres, √™tre en mesure d'√©valuer
la pertinence scientifique des mod√®les ou permettre aux
acteurs n'ayant pas ces moyens techniques et humains
de pouvoir tout de m√™me r√©utiliser ces mod√®les sur leurs
propres donn√©es.

N√©anmoins, malgr√© l'ouverture progressive de mod√®les, notamment par le biais d'une 
mise √† disposition sur la plateforme `Hugging Face`, 
des contraintes persistent pour la r√©utilisation de ces mod√®les sur des donn√©es confidentielles
dans des infrastructures internes. 
Ces r√©seaux de neurones √©tant tr√®s gourmands en calculs du fait
de leur architecture complexe (des milliards de param√®tres pour les grands mod√®les de langage),
afin d'obtenir une r√©ponse du mod√®le il est g√©n√©ralement n√©cessaire d'effectuer 
les calculs n√©cessaires par le biais de
cartes graphiques (GPU), celles-ci permettant plus de parall√©lisme dans les calculs
que les processeurs (CPU).
Cependant, depuis plusieurs ann√©es, la demande exc√®de largement l'offre, ce qui limite
l'acc√®s √† cette ressource pour de nombreux acteurs. 
Le retour √† des mod√®les plus l√©gers, pouvant √™tre exploit√©s depuis des architectures
informatiques plus accessibles, constitue l'un des [d√©fis de l'ann√©e 2024](https://www.linkedin.com/posts/julienchaumond_my-prediction-for-2024-yes-i-have-only-activity-7142887026193809409-L3i7?utm_source=share&utm_medium=member_desktop). 


Les d√©bats concernant les droits d'exploitation commerciale d'informations collect√©es
sur internet ont √©t√© nombreux en 2023. 
Apr√®s les plaintes m√©diatis√©es de _Getty Images_ (envers Stability AI), 
d'un collectif d'auteurs c√©l√®bres (envers OpenAI), la gr√®ve des acteurs √† Hollywood
contre l'exploitation de leur image par des IA et des sc√©naristes contre l'utilisation
des g√©n√©rateurs de texte, 
c'est maintenant le _New York Times_ qui a d√©pos√© en d√©cembre 2023 une plainte envers OpenAI aupr√®s de la Cour
F√©d√©rale de Manhattan.
A partir d'exemples, le journal am√©ricain met en avant le degr√© de confiance √©lev√©
que `ChatGPT` attribue aux informations issues des articles du quotidien, sans pour autant en 
citer la provenance, ni compenser financi√®rement le journal. Cela entra√Ænerait un
pr√©judice commercial du √† la r√©duction du trafic sur le site
du _New York Times_. A contrario, le journal met en avant l'effet n√©gatif sur son
image que peuvent avoir des hallucinations attribu√©es au quotidien. 
Cette plainte fait suite √† l'√©chec des n√©gociations entre les deux acteurs au cours
de l'ann√©e 2023. Ces actualit√©s relatives aux droits d'auteurs interviennent
dans un contexte o√π il s'agit de l'un des principaux axes d'intervention
de l'_"Artificial Intelligence Act"_ europ√©en (voir [Infolettre #16](/infolettre/infolettre_16)).


::: {.callout-note}
## Pour en savoir plus

- Un [article](https://www.washingtonpost.com/technology/interactive/2023/ai-chatbot-learning/?itid=mc_magnet-ai_inline_collection_1) du _Washington Post_ sur le corpus d'entra√Ænement des LLM ;
- Un [article](https://ig.ft.com/generative-ai/) du _Financial Times_ qui pr√©sente de mani√®re tr√®s
p√©dagogique la mani√®re dont fonctionnent les LLM ;
- Un [tutoriel](https://huggingface.co/docs/transformers/llm_tutorial) sur les LLM par `Hugging Face` ;
- Un [article](https://www.nytimes.com/2023/08/16/technology/ai-gpu-chips-shortage.html) du _New York Times_ sur 
la p√©nurie de GPU ;
- Un article du site sp√©cialis√© _[The Verge](https://www.theverge.com/2023/12/4/23988403/getty-lawsuit-stability-ai-copyright-infringement)_
sur les derni√®res √©volutions de la plainte de _Getty Images_ ; 
- Un article de [_Courrier International_](https://www.courrierinternational.com/article/litterature-george-r-r-martin-jonathan-franzen-et-john-grisham-partent-en-guerre-contre-chatgpt) sur la plainte d'un collectif d'auteurs envers OpenAI ;
- _New York Times vs OpenAI_ par [le _Monde_](https://www.lemonde.fr/pixels/article/2023/12/27/le-new-york-times-poursuit-en-justice-microsoft-et-openai-createur-de-chatgpt-pour-violation-de-droits-d-auteur_6207946_4408996.html
) et le [_New York Times_](https://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html).
- Les chartes relatives au contenu produit par des IA g√©n√©ratives du [gouvernement britannique](https://www.gov.uk/government/publications/generative-ai-framework-for-hmg/generative-ai-framework-for-hmg-html) et d'une vingtaine de m√©dias fran√ßais
recens√©s par l'[INA](https://larevuedesmedias.ina.fr/les-medias-face-lintelligence-artificielle-20-chartes-passees-au-crible).
:::


### Des avanc√©es scientifiques en arri√®re plan


Dans le domaine des IA g√©n√©ratives, 
deux avanc√©es moins m√©diatis√©es mais n√©anmoins fondamentales 
ont fait l'objet de d√©bats scientifiques int√©ressants. Ces
deux avanc√©es m√©thodologiques sont r√©sum√©es par
deux acronymes de trois lettres:
**RAG (_Retrieval Augmented Generation_)** et **DPO (_Direct Preference Optimization_)**. 

Ces deux techniques interviennent √† diff√©rents niveaux dans le cycle de vie d'une
IA g√©n√©ratrice, √©voqu√©e
par Andrew Karpathy dans sa vid√©o ["State of GPT"](https://www.youtube.com/watch?v=bZQun8Y4L2A): 

![R√©sum√© du _pipeline_ de construction d'un mod√®le type GPT par Andrew Karpathy dans sa vid√©o ["State of GPT"](https://www.youtube.com/watch?v=bZQun8Y4L2A)](karpathyGPT.png)

Le __RAG (_retrieval augmentated generation_)__ est une mani√®re d'enrichir
la base de connaissance d'un r√©seau de neurones pour limiter sa tendance √† l'hallucination
et augmenter la pertinence des r√©ponses.
Cela intervient ainsi au niveau du 2e pilier du _pipeline_ propos√©
par Andrew Karpathy (_"Supervised Finetuning"_) en 
substitut ou en compl√©ment du r√©entrainement (_fine tuning_).
L'objectif est de fournir au mod√®le une base de donn√©es faisant
office de contexte suppl√©mentaire au corpus d'entrainement pour am√©liorer
la pertinence des r√©ponses.

La **DPO (_Direct Preference Optimization_)** intervient quant √† elle √† un niveau plus tardif dans le
cycle de vie d'un mod√®le. Il s'agit de simplifier la prise en compte de retours sur la qualit√©
de la pr√©diction en ne dissociant plus les troisi√®me
et quatri√®me piliers du _pipeline_ de
Karpathy (_reward modeling_ et _reinforcement learning_). L'objectif de la DPO
est de cr√©er une int√©gration plus directe des retours sur la qualit√© d'un mod√®le
que ne le permettait le _reinforcement learning with human feedback_ (RLHF),
la technique dominante au d√©but de l'ann√©e 2023.
Cette probl√©matique de 
supervision et d'am√©lioration continue d'un mod√®le
d√©passe d'ailleurs le cadre des mod√®les de langage: afin de
s'assurer que les algorithmes ne perdent pas en qualit√©, l'√©valuation
humaine par le biais, par exemple, de campagnes de labellisation
ou de retours des utilisateurs, est
un enjeu important dans le cycle de vie de tout mod√®le
mis en production.

![Une illustration de la diff√©rence entre les deux approches (source: [https://arxiv.org/pdf/2305.18290.pdf](https://arxiv.org/pdf/2305.18290.pdf) et [HuggingFace](https://huggingface.co/blog/pref-tuning))](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/pref_tuning/dpo.png)

::: {.callout-note}
## Pour en savoir plus

- La vid√©o ["State of GPT"](https://www.youtube.com/watch?v=bZQun8Y4L2A) par Andrew Karpathy ;
- Un [tutoriel](https://huggingface.co/blog/ray-rag) sur le RAG par _Hugging Face_ ; 
qui permet de construire des applications utilisant des LLM par le biais de `Python` ;
- Le [blog](https://openai.com/research/learning-from-human-preferences) pr√©sentant la technique du _Reinforcement learning with human feedbacks_ par OpenAI ;
- L'[article acad√©mique](https://arxiv.org/pdf/2305.18290.pdf) pr√©sentant la DPO et un [tutoriel](https://huggingface.co/blog/pref-tuning)
d'_Hugging Face_.
- Un [article de blog](https://www.deeplearning.ai/the-batch/issue-231/) d'Andrew Ng sur la DPO.
:::


### Les bases de donn√©es vectorielles gagnent en popularit√©

En ce qui concerne les outils, `Python` reste le [point d'entr√©e de r√©f√©rence](https://www.tiobe.com/tiobe-index/)
dans le domaine de la _data science_.
Pour des besoins plus sp√©cialis√©s, des logiciels 
d√©di√©s viennent s'int√©grer √† ce langage. 

C'est le cas notamment
des bases de donn√©es vectorielles
comme [`ChromaDB`](https://www.trychroma.com/). 
Ces bases facilitent la recherche
de similarit√© entre documents textuels en exploitant
des transformations de 
ceux-ci en vecteurs num√©riques (technique des [_embeddings_](https://ig.ft.com/generative-ai/)).

Par exemple, dans l'image ci-dessous, une base de donn√©es vectorielle pourra 
√©valuer la similarit√© entre les termes en utilisant
des techniques d'alg√®bre lin√©aire de mani√®re plus efficace que ne le permettrait
`Python`, un langage trop g√©n√©raliste pour pouvoir faire cette recherche de similarit√©
dans des corpus massifs. 

![Un exemple d'_embedding_ et de rapprochement de textes. Source: [_Financial Times_](https://ig.ft.com/generative-ai/).](embeddings.png)



::: {.callout-note}
## Pour en savoir plus

- Le _framework_ [`LangChain`](https://www.langchain.com/) pour construire
par le biais de `Python`
des applications utilisant des LLM: cr√©ation d'une interface
pour poser des questions √† un LLM, transformation de la question en vecteur num√©rique par
le biais d'une base vectorielle comme `ChromaDB`, interrogation du LLM, renvoie √† l'utilisateur d'une r√©ponse...   ;
- Un [tutoriel de realpython.com](https://realpython.com/chromadb-vector-database/) sur [`ChromaDB`](https://www.trychroma.com/).
:::



## `DuckDB`: le petit canard au service des _data scientists_

Dans le domaine de l'analyse de donn√©es, 
cette ann√©e a √©t√© marqu√©e par la mont√©e en puissance de `DuckDB`
comme outil de traitement de donn√©es volumineuses. 
`DuckDB` est un logiciel qui est utilisable par le biais
des principaux langages maitris√©s par les 
_data scientists_: [`Python`](XXX), [`R`](XXX), [`JavaScript`](XX) ou directement en ligne de commande. 

Sa capacit√© √† g√©rer de grandes quantit√©s de donn√©es en faisant des requ√™tes SQL optimis√©es
rend `DuckDB` particuli√®rement appropri√© pour le traitement de donn√©es de taille interm√©diaires telles que les
donn√©es administratives.
`DuckDB` est pens√© pour le traitement de donn√©es stock√©es sur des fichiers, ce qui le distingue 
de l'approche plus exigeante du point de vue de l'infrastructure, des 
syst√®mes de gestion de base de donn√©es (SGBD) du type `PostGreSQL` (voir la partie plus technique). 
Pour des utilisateurs de l'√©cosyst√®me de l'_open data_, ou pour des organisations
dont le patrimoine de donn√©es prend plus la forme de fichiers que de bases `PostGreSQL`,
`DuckDB` est
une opportunit√© technologique permettant de
valoriser des donn√©es dont le traitement et la diffusion n√©cessitait jusqu'√† pr√©sent des ressources
computationnelles importantes. 

Dans le domaine de la diffusion des donn√©es _open data_, l'Insee a exp√©riment√© ce format
√† deux reprises pendant l'ann√©e 2023. En premier lieu, pour la diffusion des
donn√©es du [R√©pertoire Electoral Unique](https://www.insee.fr/fr/metadonnees/source/serie/s1046). 
Plus r√©cemment, ce sont les donn√©es d√©taill√©es du recensement de la population
qui ont √©t√© diffus√©es dans ce format, accompagn√©es d'un [guide sur ce blog](/post/parquetRP) (lien [Infolettre #16](/infolettre/infolettre_16)). 

<details>

<summary>

_Quelques exemples de retours sur la publication des donn√©es d√©taill√©es du recensement au format `Parquet`._

</summary>

:::: {.columns}

::: {.column width="50%"}
![](https://git.lab.sspcloud.fr/ssplab/parquet_insee_contact/-/raw/master/img/retour_utilisateur_1.png){width=700px}
:::

::: {.column width="50%"}
![](https://git.lab.sspcloud.fr/ssplab/parquet_insee_contact/-/raw/master/img/retour_utilisateur_2.png){width=700px}
:::

::::

:::: {.columns}

::: {.column width="50%"}
![](https://git.lab.sspcloud.fr/ssplab/parquet_insee_contact/-/raw/master/img/img3.png){width=700px}
:::

::: {.column width="50%"}
![](https://git.lab.sspcloud.fr/ssplab/parquet_insee_contact/-/raw/master/img/img4.png){width=700px}
:::

::::

</details>

::: {.callout-note}
## Pour en savoir plus

Ressources techniques: 

- Un [_notebook_ {{< fa brands r-project >}}](https://datalab.sspcloud.fr/launcher/ide/rstudio-sparkr?autoLaunch=true&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2FInseeFrLab%2Fformation-bceao%2Fmain%2Ftp%2Finit-tp.sh%C2%BB&resources.limits.memory=%C2%AB100Gi%C2%BB&persistence.size=%C2%AB40Gi%C2%BB) sur `DuckDB` issu d'une [formation de l'Insee](https://inseefrlab.github.io/formation-bceao/) donn√©e √† la BCEAO ;
- Le [post de blog](/post/polars/) sur la librairie {{< fa brands python >}} `Polars`, une approche alternative √† `DuckDB` ;
- L'[explorateur de donn√©es du SSPCloud](https://datalab.sspcloud.fr/data-explorer?source=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Frecensement-de-la-population-fichiers-detail-individus-localises-au-canton-ou-ville-2020-1%2F20231023-122841%2Ffd-indcvi-2020.parquet) qui repose sur `DuckDB`.

Donn√©es diffus√©es par l'Insee au format `Parquet` :

- Les donn√©es du [R√©pertoire Electoral Unique](https://www.data.gouv.fr/fr/datasets/bureaux-de-vote-et-adresses-de-leurs-electeurs/#/resources)
- Le guide d‚Äôutilisation des donn√©es du recensement de la population au format Parquet sous forme de [billet de blog](/post/parquetRP/). 
Voir aussi l'[_infolettre #16_](/infolettre/infolettre_16)

Sur le format `Parquet` :

- Un [article](https://www.insee.fr/fr/information/7635827?sommaire=7635842) sur le format `Parquet` dans le _Courrier des stats n¬∞9_
√©crit par Alexis Dondon et Pierre Lamarche ;
- Le blog d'[Eric Mauvi√®re](https://www.icem7.fr/outils/3-explorations-bluffantes-avec-duckdb-1-interroger-des-fichiers-distants/) qui pr√©sente
une s√©rie d'articles sur le format `Parquet`;
- La [pr√©sentation](https://www.linkedin.com/feed/update/urn:li:activity:7133760348129505281?updateEntityUrn=urn%3Ali%3Afs_feedUpdate%3A%28V2%2Curn%3Ali%3Aactivity%3A7133760348129505281%29
) de Romain Lesur sur le sujet pour l'atelier _Modernisation of Official Statistics_ de l'UNECE.

:::

::: {.callout-tip collapse="true"}
## Des √©l√©ments plus techniques

Il existe principalement deux approches pour stocker, organiser et mettre 
√† disposition des jeux de donn√©es
structur√©s sous forme tabulaire: les __fichiers__ et les __bases de donn√©es relationnelles__. 

Les bases de donn√©es rel√®vent d'une approche syst√©mique.
Un syst√®me de gestion de base de donn√©es (SGBD) 
est un logiciel qui g√®re √† la fois le stockage d‚Äôun ensemble de donn√©es reli√©es,
permet de mettre √† jour celles-ci (ajout ou suppression d‚Äôinformations, modification des caract√©ristiques d‚Äôune table‚Ä¶)
et qui g√®re √©galement les modalit√©s d‚Äôacc√®s √† la donn√©e (type de requ√™te, utilisateurs ayant les droits en lecture ou en √©criture...).
L'un des logiciels les plus connus dans le domaine est `PostgreSQL`. 

D'un autre c√¥t√©, le stockage de donn√©es tabulaires sous forme de fichiers offre une approche plus d√©centralis√©e et flexible. 
Par rapport √† des bases de donn√©es, les fichiers
sont plus faciles √† cr√©er, partager et stocker et ne n√©cessitent pas syst√©matiquement
des logiciels sp√©cialis√©s pour leur manipulation.
Le stockage sous la forme de fichier consiste √† organiser l'information
pr√©sente dans un jeu de donn√©es dans des fichiers, de mani√®re brute.
Ces donn√©es peuvent √™tre analys√©es sans recourir √† un logiciel sp√©cialis√©. 
M√™me dans le cadre de formats propri√©taires, comme le `.xlsx`
ou `sas7bdat`, le fait d'avoir une certaine forme de standardisation
rend possible, m√™me si ce n'est jamais parfaitement fiable, de lire ces donn√©es
avec un autre logiciel que celui pr√©vu initialement. 

La logique de la base de donn√©es est donc tr√®s diff√©rente de celle du fichier.
Par rapport √† une base de donn√©es, l'approche des fichiers pr√©sente plusieurs
avantages, √† condition de privil√©gier des formats libres.

En premier lieu, les fichiers sont
moins adh√©rents √† un logiciel gestionnaire.
Une transition d'un logiciel de traitement vers un autre
n'implique pas de changer la source brute. 
Les _data scientists_ utilisateurs de `Python` ou `R` sont confront√©s √† un
deuxi√®me inconv√©nient des bases de donn√©es.
Le traitement des bases de donn√©es n√©cessite l‚Äôinterm√©diation du logiciel de gestion
adapt√© 
l√† o√π, avec des fichiers, on peut se contenter d‚Äôune librairie,
donc un syst√®me beaucoup plus l√©ger, qui sait comment transformer la donn√©e pour la retravailler depuis `Python` ou `R`. 

Pour ces raisons, entre autres, il est plus pratique pour des utilisateurs finaux de donn√©es
d'avoir acc√®s √† des fichiers plut√¥t qu'√† des bases de donn√©es, √† condition d'avoir
les ressources computationnelles suffisantes pour pouvoir traiter ces fichiers. 

N√©anmoins, cette condition d'acc√®s √† des ressources computationnelles suffisantes
peut repr√©senter une contrainte limitante dans un environnement o√π les donn√©es
sont de volume croissant.
Dans les environnements o√π la volum√©trie des donn√©es √©tait importante, 
les bases de donn√©es ont connu une certaine
popularit√© puisqu'elles permettaient de
g√©rer efficacement de grandes quantit√©s de donn√©es. Comme, de plus, les bases
de donn√©es offraient une gestion plus fine et fiable
des droits d'acc√®s et d'√©criture sur les bases que ne le permettent des fichiers, 
cette approche a pu conna√Ætre une certaine popularit√©. 

Le d√©veloppement conjoint
de formats de stockages orient√©s
objets (comme le protocole `S3`, utilis√© par les syst√®mes _cloud_ modernes √† l'image
du `SSPCloud`)
et d'outils de traitement efficaces comme `DuckDB` permet d'associer
les avantages de ce dernier √† ceux d'un syst√®me
coh√©rent de fichiers partag√©s (lecture/√©criture optimis√©es, dissociation
des utilisateurs pouvant lire et √©crire un fichier...).  

Techniquement, `DuckDB` fonctionne de mani√®re optimale avec des fichiers au format `Parquet`.
Ce format de donn√©es, orient√© colonne, permet en effet d'optimiser des traitements
classiques des _data scientists_: s√©lectionner seulement certaines colonnes d'un jeu de
donn√©es, regrouper des donn√©es pour faire des calculs d'agr√©gats, etc. 

![Une illustration du principe du stockage orient√© colonne (Source: [Michael Berk](https://towardsdatascience.com/demystifying-the-parquet-file-format-13adb0206705))](parquet.png)

Par exemple, dans le sch√©ma ci-dessus, si on ne s'int√©resse qu'aux dates enregistr√©es,
il suffit de ne prendre que le bloc de donn√©es _ad hoc_. Il n'est pas n√©cessaire
de lire tout le fichier pour ne garder que les dates, comme ce serait le cas
avec un format CSV. 


:::


## De la _data science_ depuis un navigateur

Le gain de popularit√© de `DuckDB` au cours de l'ann√©e 2023
s'explique en partie gr√¢ce √† sa version web qui permet
d'ex√©cuter des traitements de donn√©es par le biais de
navigateurs web, sans avoir √† installer de logiciel 
sp√©cialis√© comme `Python` {{< fa brands python >}} ou {{< fa brands r-project >}}. C'est une approche typique du [_web assembly_](https://developer.mozilla.org/fr/docs/WebAssembly) 
qui consiste √† mettre √† disposition des logiciels de calculs scientifiques par le biais d'un simple navigateur
gr√¢ce √† `Javascript` {{< fa brands js-square >}}, qui est disponible sur tout navigateur.

D'ailleurs, il est maintenant possible de faire du `R` directement depuis
un navigateur _web_ gr√¢ce √† [`webR`](https://docs.r-wasm.org/webr/latest/),
une librairie d√©velopp√©e par _Posit_ en 2023 et qui
porte la grammaire `R` dans le navigateur (exemple √† tester üëáÔ∏è)
L'id√©e est que le code d'analyse de donn√©es est en `R`
mais que c'est du `Javascript` qui servira, en arri√®re-plan, √† l'ex√©cution.
La librairie est encore jeune mais est prometteuse pour faciliter la transition
entre du code d'analyse de donn√©es en `R` et une application interactive. 

<!----
laisser tomber ce paragraphe ?
Amener les logiciels statistiques dans le navigateur
est une inversion de l'approche ant√©rieure qui consistait √† encapsuler du
`Javascript` dans des applications `R` comme le pr√©voit
`Shiny`. 
Cette approche, qui appara√Æt attractive au premier abord 
puisqu'elle permet de relier une 
application interactive √† des traitements sur des donn√©es, pr√©sente l'inconv√©nient
d'√™tre exigeante lorsqu'il est n√©cessaire de partager cette application. 
Pour qu'une application `Shiny` renvoie une r√©ponse √† la personne qui y acc√®de
par le biais d'un navigateur web, il faut connecter l'application √† un serveur 
effectuant des calculs `R` ce qui n√©cessite l'utilisation de
services sp√©cialis√©s ou la mise en place de ressources de calculs
d√©di√©es. Avec [`webR`](https://docs.r-wasm.org/webr/latest/) ou 
son √©quivalent `Python` [`pyodide`](https://pyodide.org/en/stable/),
la mise en ligne ne n√©cessite pas ......
---->



```{webr-r}
head(mtcars)

fit = lm(mpg ~ am, data = mtcars)

summary(fit)
```

Un exemple plus complexe, utilisant le _package_ `ggplot2`:

```{webr-r}
library("ggplot2")

ggplot(mpg, aes(displ, hwy, colour = class)) + 
  geom_point()
```


::: {.callout-note}
## Pour en savoir plus

- La [documentation officielle](https://docs.r-wasm.org/webr/latest/) de `WebR` ;
- [Un _post_](https://thinkr.fr/retour-vers-le-turfu-r-le-web-et-webr/) didactique sur le _web assembly_ par _ThinkR_ ;
- L'extension [`quarto-webR`](https://quarto-webr.thecoatlessprofessor.com/)
qui permet d'encapsuler du code `webR` dans un site web statique construit
avec `Quarto` ;
- Une [d√©monstration](https://observablehq.com/@hrbrmstr/webr-0-2-2-in-observable)
de `WebR` sur `Observable`.
:::
