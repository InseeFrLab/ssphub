---
title: Infolettre n°17
description: |
  Infolettre, __Janvier 2024__

# Date published
date: '2024-01-20'
number: 17

image: learning.png

authors:
  - Lino Galiana

tags:
  - infolettre

categories:
  - Infolettre
---

![](learning.png){width=50% fig-align="center"}

:::{.callout-tip}

__*Vous désirez intégrer la liste de diffusion ? L'inscription se fait [ici](https://framaforms.org/integration-reseau-des-data-scientists-1676407156).*__

:::



## Panorama des enjeux de 2023 dans le domaine de l'Intelligence Artificielle

### Les IA génératives toujours au coeur des débats

Dans la continuité
de la sortie de ChatGPT en décembre 2022, les IA génératives sont restées très
médiatisées en 2023. Celles-ci ont focalisé une part importante de l'attention portée
à la _data science_. 
Outre la publication de GPT-4 en mars (modèle embarqué dans la version Pro de ChatGPT),
de nombreux grands modèles de langage (LLM) généralistes ont été publiés cette année:
Llama-2 (Méta), Mixtral 7B (Mistral), Falcon 180B (Technology Innovation Institute), PaLM 2 (Google)...
Ces publications ont permis de mettre en avant le caractère
stratégique de la mise à disposition de modèles _open source_. 

La récupération et la structuration de corpus massifs,
l'entraînement de modèles intégrant des
milliards de paramètres et l'évaluation _ex post_ de ceux-ci étant à la portée d'un
nombre restreint d'acteur,
la publication en _open source_ de modèles et de codes sources
est en effet indispensable pour, entre autres, être en mesure d'évaluer
la pertinence scientifique des modèles ou permettre aux
acteurs n'ayant pas ces moyens techniques et humains
de pouvoir tout de même réutiliser ces modèles sur leurs
propres données sans dépendre d'acteurs spécialisés.

Néanmoins, malgré l'ouverture progressive de modèles, notamment par le biais d'une 
mise à disposition sur la plateforme `Hugging Face`, 
des contraintes persistent pour la réutilisation de ces modèles sur des données confidentielles
dans des infrastructures internes. 
Les réseaux de neurone étant très gourmands en calculs du fait
de leur architecture complexe (des milliards de paramètres pour les grands modèles de langage),
pour obtenir une réponse du modèle, il est généralement nécessaire d'effectuer 
les calculs nécessaires par le biais de
cartes graphiques (GPU), celles-ci permettant plus de parallélisme dans les calculs
que les processeurs (CPU).
Cependant, depuis plusieurs années, la demande excède largement l'offre, ce qui limite
l'accès à des GPU pour de nombreux acteurs. 
Le retour à des modèles plus légers, pouvant être exploités depuis des architectures
informatiques plus accessibles, constitue l'un des [défis de l'année 2024](https://www.linkedin.com/posts/julienchaumond_my-prediction-for-2024-yes-i-have-only-activity-7142887026193809409-L3i7?utm_source=share&utm_medium=member_desktop). 


Les débats concernant les droits d'exploitation commerciale d'informations collectées
sur internet ont été relancés à la fin de l'année 2023. 
Après les plaintes médiatisées de Getty Images (envers Stability AI), 
d'un collectif d'auteurs célèbres (envers OpenAI), la grève des acteurs à Hollywood
contre l'exploitation de leur image par des AI et des scénaristes contre l'utilisation
des générateurs de texte, 
c'est cette fois le _New York Times_ qui dépose une plainte envers OpenAI auprès de la Cour
Fédérale de Manhattan.
A partir d'exemples, le journal américain met en avant le degré de confiance
qu'apporte `ChatGPT` aux informations issues des articles du quotidien mais
dont il ne cite pas la provenance, ce qui réduit le trafic potentiel sur le site
du _New York Times_. A contrario, le journal met en avant l'effet négatif sur son
image que peuvent avoir des hallucinations attribuées au quotidien. 
Cette plainte fait suite à l'échec des négociations entre les deux acteurs au cours
de l'année 2023. Ces actualités relatives aux droits d'auteurs interviennent
dans un contexte où il s'agit de l'un des principaux axes d'intervention
de l'_"Artificial Intelligence Act"_ européen (voir [Infolettre #16](/infolettre/infolettre_16)).


::: {.callout-note}
## Pour en savoir plus

- Un [tutoriel](https://huggingface.co/docs/transformers/llm_tutorial) sur les LLM par `Hugging Face` ;
- Un [article](https://www.nytimes.com/2023/08/16/technology/ai-gpu-chips-shortage.html) du _New York Times_ sur 
la pénurie de GPU ;
- Un article du site spécialisé _[The Verge](https://www.theverge.com/2023/12/4/23988403/getty-lawsuit-stability-ai-copyright-infringement)_
sur les dernières évolutions de la plainte de _Getty Images_ ; 
- Un article de [_Courrier International_](https://www.courrierinternational.com/article/litterature-george-r-r-martin-jonathan-franzen-et-john-grisham-partent-en-guerre-contre-chatgpt) sur la plainte des auteurs envers OpenAI ;
- _New York Times vs OpenAI_ par [le _Monde_](https://www.lemonde.fr/pixels/article/2023/12/27/le-new-york-times-poursuit-en-justice-microsoft-et-openai-createur-de-chatgpt-pour-violation-de-droits-d-auteur_6207946_4408996.html
) et le [_New York Times_](https://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html).
- Les chartes relatives au contenu produit par des IA génératives du [gouvernement britannique](https://www.gov.uk/government/publications/generative-ai-framework-for-hmg/generative-ai-framework-for-hmg-html) et d'une vingtaine de médias français
recensés par l'[INA](https://larevuedesmedias.ina.fr/les-medias-face-lintelligence-artificielle-20-chartes-passees-au-crible).
:::


### Des avancées scientifiques en arrière plan


Si les IA génératives ont fait la une, 
deux avancées moins médiatisées mais néanmoins fondamentales 
ont fait l'objet de débats scientifiques intéressants. Ces
deux avancées méthodologiques sont deux acronymes de trois lettres:
RAG (_retrieval augmentated generation_) et DPO (_Direct Preference Optimization_). 

Elles interviennent à différents niveaux dans le cycle de vie d'une
IA génératrice :

![Résumé du _pipeline_ de construction d'un modèle type GPT par Andrew Karpathy dans sa vidéo ["State of GPT"](https://www.youtube.com/watch?v=bZQun8Y4L2A)](karpathyGPT.png)

Le __RAG (_retrieval augmentated generation_)__ est une manière d'enrichir
la base de connaissance d'un réseau de neurone pour limiter sa tendance à l'hallucination
et augmenter la pertinence des réponses.
Cela intervient donc ainsi au niveau du 2e pilier du _pipeline_ proposé par Andrew Karpathy en 
substitut ou en complément du réentrainement.
L'objectif est de fournir au modèle une base de données faisant
office de contexte supplémentaire au corpus d'entrainement pour améliorer
la pertinence des réponses.

La **DPO (_Direct Preference Optimization_)** intervient quant à elle à un niveau plus tardif dans le
cycle de vie d'un modèle. Il s'agit de simplifier la prise en compte de retours sur la qualité
de la prédiction en ne dissociant plus les troisième
et quatrième piliers du _pipeline_ de Karpathy. L'objectif de la DPO
est de créer une intégration plus directe des retours sur la qualité d'un modèle
que ne le permettait le _reinforcement learning with human feedback_ (RLHF),
la technique dominante au début de l'année 2023.
Cette problématique de 
supervision et d'amélioration continue d'un modèle
dépasse d'ailleurs le cadre des modèles de langage: afin de
s'assurer que les algorithmes ne perdent pas en qualité, l'évaluation
humaine par le biais, par exemple, de campagnes de labellisation
ou de retours des utilisateurs, est
un enjeu important dans le cycle de vie d'un modèle.

![Une illustration de la différence entre les deux approches (source: [https://arxiv.org/pdf/2305.18290.pdf](https://arxiv.org/pdf/2305.18290.pdf) et [HuggingFace](https://huggingface.co/blog/pref-tuning))](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/pref_tuning/dpo.png)



::: {.callout-note}
## Pour en savoir plus

- La vidéo ["State of GPT"](https://www.youtube.com/watch?v=bZQun8Y4L2A) par Andrew Karpathy ;
- Un [tutoriel](https://huggingface.co/blog/ray-rag) sur le RAG par _Hugging Face_ ; 
- Le _framework_ [`LangChain`](https://www.langchain.com/) qui permet
qui permet de construire des applications utilisant des LLM par le biais de `Python` ;
- Le [blog](https://openai.com/research/learning-from-human-preferences) présentant la technique du _Reinforcement learning with human feedbacks_ par OpenAI ;
- L'[article académique](https://arxiv.org/pdf/2305.18290.pdf) présentant la DPO et un [tutoriel](https://huggingface.co/blog/pref-tuning)
d'_Hugging Face_.
- Un [article de blog](https://www.deeplearning.ai/the-batch/issue-231/) d'Andrew Ng sur la DPO.
:::


## `DuckDB`

Dans le domaine de l'analyse de données traditionnelles, 
cette année a été marquée par la montée en puissance de `DuckDB`
comme outil de traitement de données volumineuses. 
`DuckDB` est un logiciel qui est utilisable par le biais de librairies
clientes dans les principaux langages maitrisés par les 
_data scientists_: [`Python`](XXX), [`R`](XXX), [`JavaScript`](XX) ou directement en ligne de commande. 

Sa capacité à gérer de grandes quantités de données en faisant des requêtes SQL optimisées
rend `DuckDB` particulièrement approprié pour le traitement de données de taille intermédiaires du type
données administratives.
`DuckDB` est pensé pour le traitement de données sur des fichiers, ce qui le distingue 
de l'approche plus systémique, et donc plus exigeant du point de vue de l'infratructure, des  
système de gestion de base de données (SGBD) du type `PostGreSQL` (voir la partie plus technique). 
Pour des utilisateurs de l'écosystème de l'_open data_, ou pour des organisations
dont le patrimoine de données prend plus la forme de fichiers que de bases PostGreSQL,
`DuckDB` représente
une opportunité de saut de grenouille
pour valoriser des données qui nécessitaient autrement des ressources
computationnelles importantes. 

Techniquement, `DuckDB` fonctionne de manière optimale avec des fichiers au format `Parquet`.
Ce format de données, orienté colonne, permet en effet d'optimiser des traitements
classiques des _data scientists_: sélectionner seulement certaines colonnes d'un jeu de
données, regrouper des données pour faire des calculs d'agrégats, etc. 

![Une illustration du principe du stockage orienté colonne (Source: [Michael Berk](https://towardsdatascience.com/demystifying-the-parquet-file-format-13adb0206705))](parquet.png)

Dans le domaine de la diffusion des données _open data_, l'Insee a expérimenté ce format
à deux reprises pendant l'année 2023. En premier lieu, pour la diffusion des
données du [Répertoire Electoral Unique](https://www.insee.fr/fr/metadonnees/source/serie/s1046). 
Plus récemment, ce sont les données détaillées du recensement de la population
qui ont été diffusées dans ce format, accompagnées d'un guide sur ce blog (lien newsletter #16). 
__tobecontinued__

::: {.callout-note}
## Pour en savoir plus

Ressources techniques: 

- Un [_notebook_ {{< fa brands r-project >}}](https://datalab.sspcloud.fr/launcher/ide/rstudio-sparkr?autoLaunch=true&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2FInseeFrLab%2Fformation-bceao%2Fmain%2Ftp%2Finit-tp.sh%C2%BB&resources.limits.memory=%C2%AB100Gi%C2%BB&persistence.size=%C2%AB40Gi%C2%BB) sur `DuckDB` issu d'une [formation de l'Insee](https://inseefrlab.github.io/formation-bceao/) donnée à la BCEAO ;
- Le [post de blog](/post/polars/) sur la librairie {{< fa brands python >}} `Polars`, une approche alternative à `DuckDB` ;
- L'[explorateur de données du SSPCloud](https://datalab.sspcloud.fr/data-explorer?source=https%3A%2F%2Fstatic.data.gouv.fr%2Fresources%2Frecensement-de-la-population-fichiers-detail-individus-localises-au-canton-ou-ville-2020-1%2F20231023-122841%2Ffd-indcvi-2020.parquet) qui repose sur `DuckDB`.

Données diffusées par l'Insee au format `Parquet` :

- Les données du [Répertoire Electoral Unique](https://www.data.gouv.fr/fr/datasets/bureaux-de-vote-et-adresses-de-leurs-electeurs/#/resources)
- Le guide d’utilisation des données du recensement de la population au format Parquet sous forme de [billet de blog](/post/parquetRP/). 
Voir aussi l'[_infolettre #16_](/infolettre/infolettre_16)

Sur le format `Parquet` :

- Un [article](https://www.insee.fr/fr/information/7635827?sommaire=7635842) sur le format `Parquet` dans le _Courrier des stats n°9_
écrit par Alexis Dondon et Pierre Lamarche ;
- Le blog d'[Eric Mauvière](https://www.icem7.fr/outils/3-explorations-bluffantes-avec-duckdb-1-interroger-des-fichiers-distants/) qui présente
une série d'articles sur le format `Parquet`;
- La [présentation](https://www.linkedin.com/feed/update/urn:li:activity:7133760348129505281?updateEntityUrn=urn%3Ali%3Afs_feedUpdate%3A%28V2%2Curn%3Ali%3Aactivity%3A7133760348129505281%29
) de Romain Lesur sur le sujet pour l'atelier _Modernisation of Official Statistics_ de l'UNECE.

:::

::: {.callout-tip collapse="true"}
## Des éléments plus techniques

Il existe principalement deux approches pour stocker, organiser et mettre 
à disposition des jeux de données
structurés sous forme tabulaire: les __fichiers__ et les __bases de données relationnelles__. 

Les bases de données relèvent d'une approche systémique.
Un système de gestion de base de données (SGBD) 
est un logiciel qui gère à la fois le stockage d’un ensemble de données reliées,
permet de mettre à jour celles-ci (ajout ou suppression d’informations, modification des caractéristiques d’une table…)
et qui gère également les modalités d’accès à la donnée (type de requête, utilisateurs ayant les droits en lecture ou en écriture...).
L'un des logiciels les plus connus dans le domaine est `PostgreSQL`. 

D'un autre côté, le stockage de données tabulaires sous forme de fichiers offre une approche plus décentralisée et flexible. 
Par rapport à des bases de données, les fichiers
sont plus faciles à créer, partager et stocker et ne nécessitent pas systématiquement
des logiciels spécialisés pour leur manipulation.
Le stockage sous la forme de fichier consiste à organiser l'information
présente dans un jeu de données dans des fichiers, de manière brute.
Ces données peuvent être analysées sans recourir à un logiciel spécialisé. 
Même dans le cadre de formats propriétaires, comme le `.xlsx`
ou `sas7bdat`, le fait d'avoir une certaine forme de standardisation
rend possible, même si ce n'est jamais parfaitement fiable, de lire ces données
avec un autre logiciel que celui prévu initialement. 

La logique de la base de données est donc très différente de celle du fichier.
Par rapport à une base de données, l'approche des fichiers présente plusieurs
avantages, à condition de privilégier des formats libres.

En premier lieu, les fichiers sont
moins adhérents à un logiciel gestionnaire.
Une transition d'un logiciel de traitement vers un autre
n'implique pas de changer la source brute. 
Les _data scientists_ utilisateurs de `Python` ou `R` rencontrent un
deuxième inconvénient aux bases de données par rapport aux fichiers.
Les bases de données nécessitent l’intermédiation du logiciel de gestion
adapté 
là où, avec des fichiers, on peut se contenter d’une librairie,
donc un système beaucoup plus léger, qui sait comment transformer la donnée pour la retravailler depuis `Python` ou `R`. 

Pour ces raisons, entre autres, il est plus pratique pour des utilisateurs finaux de données
d'avoir accès à des fichiers plutôt qu'à des bases de données, à condition d'avoir
les ressources computationnelles suffisantes pour pouvoir traiter ces fichiers. 

Néanmoins, cette condition d'accès à des ressources computationnelles suffisantes
peut représenter une contrainte limitante dans un environnement où les données
sont de volume croissant.
Dans les environnements où la volumétrie des données était importante, 
les bases de données ont connu une certaine
popularité puisqu'elles permettaient de
gérer efficacement de grandes quantités de données. Comme, de plus, les bases
de données offraient une gestion plus fine et fiable
des droits d'accès et d'écriture sur les bases que ne le permettent des fichiers, 
cette approche a pu connaître une certaine popularité. 

Le développement conjoint
de formats de stockages orientés
objets (comme le protocole S3, utilisé par les systèmes _Cloud_ modernes à l'image
du SSPCloud)
et d'outils de traitement efficaces comme DuckDB permettent 
de 

:::



## WASM
