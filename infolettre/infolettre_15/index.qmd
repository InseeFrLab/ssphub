---
title: Infolettre n¬∞15
description: |
  Infolettre de rentr√©e, __Septembre 2023__

# Date published
date: '2023-09-10'
number: 15

image: learning.png

authors:
  - Lino Galiana

tags:
  - infolettre

categories:
  - Infolettre
---

![](learning.png){width=50% fig-align="center"}

:::{.callout-tip}

__*Vous d√©sirez int√©grer la liste de diffusion ? L'inscription se fait [ici](https://framaforms.org/integration-reseau-des-data-scientists-1676407156).*__

:::


C'est la rentr√©e ! Comme les √©l√®ves
qui reviennent sur les bancs des √©coles,
les mod√®les de machine learning ont p√©riodiquement
besoin de mettre √† jour leurs connaissances.

Cette _newsletter_ sera donc consacr√©e aux enjeux
du r√©-entrainement et de la sp√©cialisation
de mod√®les, une question
d'actualit√© suite √† la publication estivale de 
plusieurs grands mod√®les de langage (LLM) _open source_.


::: {.callout-note}
La premi√®re partie de cette _newsletter_
se concentrera sur les
enjeux principaux. La suite sera plus technique 
et √©voquera plus en d√©tail certains mod√®les
et les m√©thodes de r√©-entrainement.  
:::

# Enjeux associ√©s au r√©entrainement des mod√®les de langage

## Un entra√Ænement _ex nihilo_ hors de port√©e

Si de nombreuses t√¢ches de mod√©lisation ne n√©cessitent pas
des mod√®les tr√®s sophistiqu√©s, deux domaines de
recherche - √† savoir le traitement naturel du langage (NLP) et l'analyse d'image -
ont connu ces derni√®res ann√©es des innovations
importantes gr√¢ce
√† des [r√©seaux de neurones](https://www.cnil.fr/fr/definition/reseau-de-neurones-artificiels-artificial-neural-network) √† 
l'architecture de plus en plus complexe. 

Pour √™tre en mesure d'entra√Æner
un mod√®le complexe, du type [grand mod√®le de langage (LLM)](https://fr.wikipedia.org/wiki/Grand_mod%C3%A8le_de_langage), il faut, _a minima_,
disposer des intrants suivants:

- Un __immense volume de donn√©es d√©structur√©es__. La constitution de
ces corpus implique le moissonnage en masse
de ressources en ligne, ce qui n'est pas sans poser des
[enjeux juridiques de propri√©t√© intellectuelle](https://www.deeplearning.ai/the-batch/time-to-update-copyright-for-generative-ai/) qui ne sont pas encore r√©solus. 
La r√©cup√©ration de ces donn√©es 
n√©cessite des ressources importantes et une bonne connaissance de la 
structure et la nature des donn√©es n√©cessaires pour entrainer un mod√®le ;
- Des __ressources informatiques hors du commun__. Les investissements importants
pour les cartes graphiques (GPU), une [ressource en p√©nurie](https://www.nytimes.com/2023/08/16/technology/ai-gpu-chips-shortage.html) et les
co√ªts courants associ√©s (√©lectricit√©, maintenance...) font qu'une poign√©e d'acteurs du num√©rique
disposent des ressources ad√©quates pour entra√Æner un mod√®le _ex nihilo_.
Cet article de [Forbes](https://www.forbes.com/sites/craigsmith/2023/09/08/what-large-models-cost-you--there-is-no-free-ai-lunch/) 
√©voque des montants de l'ordre de plusieurs millions de dollars.
- Des __experts__ aux comp√©tences √† l'intersection entre la recherche en math√©matique et informatique
ainsi que des sp√©cialistes en _data engineering_ actuellement en p√©nurie sur le march√© du travail. 

La combinaison de ces facteurs rend difficile, si ce n'est impossible,
l'entrainement _ex nihilo_ de tels mod√®les par la majorit√©
des acteurs de la donn√©e. Seule une poign√©e de centres de recherche
diposent des ressources permettant d'entra√Æner _ex nihilo_ ce type de mod√®les.

## La r√©utilisation en pratique

N√©anmoins, les besoins d'utilisation de ces mod√®les d√©passent le cercle
des acteurs en mesure de les entra√Æner. 
Plusieurs types de techniques, de [complexit√© graduelle](https://www.deeplearning.ai/the-batch/tips-for-taking-advantage-of-open-large-language-models/),
ont ainsi √©merg√© pour √™tre en mesure de r√©utiliser et am√©liorer
un mod√®le pr√©-entra√Æn√©.

Un frein √† la r√©utilisation massive de mod√®les pr√©-entra√Æn√©s est
la nature propri√©taire de certains mod√®les, dont les conditions
de r√©utilisation peuvent √™tre limitantes. Pour
cette raison, l'√©mergence de mod√®les _open source_, dont la
structure est plus transparente (on ne sait, par exemple, pas combien de param√®tres
comporte GPT-4) et dont les conditions de r√©utilisation
sur des infrastructures internes
sont moins restrictives, est devenu ces derniers mois
un enjeu important dans l'√©cosyst√®me de la donn√©e. 

Les discussions sur l'ouverture des mod√®les s'inscrivent dans le contexte d'un affrontement important entre deux visions
du mod√®le
√©conomique du secteur num√©rique : si le co-cr√©ateur d'`OpenAI` 
a pu affirmer ["_We were wrong_"](https://www.theverge.com/2023/3/15/23640180/openai-gpt-4-launch-closed-research-ilya-sutskever-interview),
un [m√©mo interne de Google](https://www.theverge.com/2023/7/10/23790132/google-memo-moat-ai-leak-demis-hassabis)
d√©fendait quant √† lui l'id√©e que les mod√®les _open source_ sont 
amen√©s √† prendre le dessus, car ils
peuvent b√©n√©ficier √† plus grande √©chelle du travail d'experts et de retours d'utilisateurs.

La publication cet √©t√© de deux
mod√®les _open source_ ([`LLaMA-2`](https://ai.meta.com/llama/) et [`Falcon`](https://falconllm.tii.ae/))
ouvre de nouvelles perspectives pour une r√©utilisation
de mod√®les dans une infrastructure interne, √† condition de
disposer des ressources computationnelles suffisantes
et d'une strat√©gie adapt√©e de r√©-apprentissage. 

Pour aller plus loin sur ce sujet, la suite de cette _newsletter_
√©voque des d√©tails plus techniques.
La _masterclass_ sur le
sujet du _fine-tuning_ que nous organisons avec `datascientest` ([plus d'informations üëáÔ∏è](#mc-datascientest))
permettra √©galement d'approfondir cette question. 


# Actualit√©s

## De nouveaux grands mod√®les de langage (LLM)

Pas de vacances pour les principaux acteurs de la _data science_ !
Ce champ de recherche appliqu√©e continue √† conna√Ætre
une actualit√© dense avec la publication, cet √©t√©, 
de deux mod√®les importants:

- [`LLaMA-2`](https://ai.meta.com/llama/) par Meta, disponible en versions 7B, 13B et 70B c'est-√†-dire, respectivement, 7, 13 et 70 milliards de param√®tres. Dans le domaine des LLM actuels, c'est donc un mod√®le plut√¥t minimaliste (`GPT-3` comportait 175 milliards de param√®tres, `GPT-4` en comporterait 1.7 trillions soit 1700 milliards). `LeBonLLM` propose, d√©j√†, des exemples de [_fine tuning_ de `LLaMa`](https://www.lebonllm.fr/entrainer-son-llm-avec-llama-1-et-llama-2/)
 ;
- [`Falcon`](https://falconllm.tii.ae/) par l'Institut d'Innovation et de Technologie d'Abu Dhabi. Alors que [Falcon-40B](https://huggingface.co/tiiuae/falcon-40b) avait d√©j√† connu un engougement important en se pla√ßant en t√™te des r√©utilisations sur `HuggingFace`, la sortie il y a quelques jours de [Falcon 180B](https://huggingface.co/tiiuae/falcon-180B), dont les performances sont proches de celles des mod√®les propri√©taires. 

Ces deux mod√®les permettent d'envisager des r√©utilisations apr√®s un r√©-entrainement sur des jeux de donn√©es _ad hoc_ pour am√©liorer leurs performances (technique du _fine tuning_). En effet, les grands mod√®les de langage sont g√©n√©ralement entra√Æn√©s
sur des corpus g√©n√©riques de langage naturel principalement issus d'internet (@tbl-corpus-falcon).
Cela les rend capables de comprendre les interactions avec des utilisateurs, notamment leurs instructions (_prompt_)
et d'interagir avec eux de mani√®re assez naturelle. N√©anmoins, pour des t√¢ches tr√®s sp√©cialis√©es ou des corpus
particuliers, ces mod√®les g√©n√©riques peuvent n√©cessiter d'√™tre sp√©cialis√©s pour obtenir de meilleures performances.

::: {.callout-note collapse="true"}
## D√©rouler pour en savoir plus sur le corpus d'entra√Ænement de `Falcon`

: _[Corpus d'entra√Ænement de Falcon 180B](https://huggingface.co/tiiuae/falcon-180B)_{#tbl-corpus-falcon}

  | Source de donn√©es | Proportion dans le corpus 
  |-----------|------------|
  | `RefinedWeb-English` (_webscraping_)	| 75%	|
  | `RefinedWeb-Europe`	(_webscraping_) | 7%	|
  | Livres |	6%	|	
  | Sites de conversations (`Reddit`, `StackOverflow`, `HackerNews`...) |	5%	|
  | Code (`Github`...)	| 5% |
  | Documents techniques (`arXiv`, `PubMed`...) |	2%	| 

:::


Ces deux mod√®les proposent des licences permissives de r√©utilisation. Celle de [`Falcon`](https://falconllm.tii.ae/)
est assez standard puisqu'il s'agit d'une [Apache 2.0](https://fr.wikipedia.org/wiki/Licence_Apache). 
Celle de [`LLaMA-2`](https://ai.meta.com/llama/) est quant √† elle moins traditionnelle. 
La r√©utilisation est libre,
y compris √† des fins commerciale, sauf pour les gros acteurs du num√©rique, globalement les concurrents
de `Meta` :

> 2. Additional Commercial Terms. If, on the Llama 2 version release date, the 
monthly active users of the products or services made available by or for Licensee, 
or Licensee's affiliates, is greater than 700 million monthly active users in the 
preceding calendar month, you must request a license from Meta, which Meta may 
grant to you in its sole discretion, and you are not authorized to exercise any of the 
rights under this Agreement unless or until Meta otherwise expressly grants you 
such rights.
>
> [Licence de LLaMa-2 sur `Github`](https://github.com/facebookresearch/llama/blob/d7e2e37e163981fd674ea2a633fac2014550898d/LICENSE#L65-L71)



## Le r√©entrainement des mod√®les

L'ouverture de ces mod√®les laisse envisager des r√©utilisations
sur de nouveaux jeux de donn√©es dans des infrastructures internes. 
Cet √©t√©, [Andrew Ng](https://www.deeplearning.ai/the-batch/tips-for-taking-advantage-of-open-large-language-models/), 
dans sa _newsletter_,
est revenu sur les m√©thodes pour affiner les performances d'un mod√®le
sur des donn√©es qu'il n'a pas rencontr√© dans son corpus d'entra√Ænement. 

- La technique la plus simple est d'__affiner les instructions__ (_prompt_) fournies √†
un mod√®le. Pour faire l'analogie avec l'apprentissage humain, pour obtenir une r√©ponse
mieux cibl√©e √† une question, il est souvent n√©cessaire de reformuler une question. 
Par exemple, lors d'une interaction avec une IA assistante de code,
il peut √™tre utile de guider un LLM avec une instruction
_"as a data scientist"_ ;
- __Fournir quelques exemples √† un mod√®le__ (_few shot learning_). De m√™me qu'avec les humains, fournir
un petit nombre d'exemples peut suffire √† un mod√®le, par un raisonnement inductif, 
√† comprendre et r√©pondre de mani√®re juste √† son instructeur. 
Selon la difficult√© de la t√¢che √† 
mettre en oeuvre, il peut suffire de tr√®s peu de cas pour sp√©cialiser un mod√®le en modifiant les derni√®res
couches du r√©seau de neurone. 
- __R√©entrainement par sp√©cialisation__ (_fine tuning_) pour affiner le mod√®le sur une t√¢che donn√©e. 
Il s'agit d'une approche qui peut ressembler √† l'apprentissage d'une nouvelle langue pour un humain: 
√† partir d'un certain stock de connaissances ant√©rieures (une langue natale), on accumule
en s√©rie des exemples bien choisis pour am√©liorer la compr√©hension d'une autre langue. 
Cette approche permet une √©conomie de ressources puisqu'elle consiste √† sp√©cialiser un mod√®le
g√©n√©raliste mais n√©cessite que la nature du probl√®me pour lequel est r√©-entrain√© un mod√®le
ressemble √† celle pour lequel le mod√®le a √©t√© entra√Æn√©. De m√™me qu'essayer de transposer des r√®gles
d'une langue latine aidera peu √† apprendre le japonais, sp√©cialiser un mod√®le d'analyse
d'image pour une t√¢che de classification de donn√©es textuelles sera inefficace. 

Le _fine tuning_ est ainsi une solution int√©ressante √† condition d'avoir test√© si des
approches plus simples n'apportent pas d√©j√† des solutions satisfaisantes.

De plus, pour √™tre en mesure de _fine tuner_ un mod√®le, outre 
l'acc√®s √† des ressources computationnelles
cons√©quentes (mais tout de m√™me moindres qu'un entra√Ænement _ex nihilo_),
beaucoup de m√©thodes n√©cessitent de disposer 
de donn√©es labellis√©es, c'est-√†-dire impliquent de poss√©der une base de donn√©es 
permettant de juger de la qualit√© des pr√©dictions du mod√®le.
Pour pallier cette absence, il est possible
de mettre en oeuvre un processus humain d'annotation et fournir au mod√®le ces √©valuations pour l'amener
√† s'am√©liorer (technique nomm√©e **_[reinforcement learning from human feedback](https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback)_**).

Comme l'√©voque encore Andrew Ng, l'acc√®s √† des mod√®les
pr√©-entra√Æn√©s change le [cycle de d√©veloppement des projets utilisateurs d'IA](https://www.deeplearning.ai/the-batch/building-machine-learning-systems-is-more-debugging-than-development/).
Ces projets ne consistent plus, comme les logiciels classiques,
√† d√©velopper en amont des sp√©cifications puis d√©ployer un mod√®le correspondant √† ces sp√©cifications
mais, au contraire, √† commencer par mettre en oeuvre rapidement un premier mod√®le dont le comportement
sera √©valu√© et am√©lior√© en continu par des m√©thodes comme l'apprentissage par renforcement. 


## Le reste de l'actualit√©

- La commission d'acc√®s aux documents administratifs (CADA) a rendu un [avis](https://www.cada.fr/20230314)
sur le sujet de la publication des poids des mod√®les d'apprentissage entra√Æn√©s par l'administration fran√ßaise ;
- Une association fran√ßaise a √©merg√© pour rassembler des ressources et offrir un espace communautaire autour des LLM
francophones: [Le Bon LLM](https://www.lebonllm.fr/) ;
- La qualit√© des r√©ponses de `ChatGPT` pourrait s'√™tre [d√©grad√©e](https://www.deeplearning.ai/the-batch/chatgpts-behavior-change-over-time/) au cours du temps ; 
- Le _Financial Times_ pr√©sente de mani√®re tr√®s p√©dagogique le [fonctionnement des LLM](https://ig.ft.com/generative-ai/) ;
- Meta publie [`Nougat`](https://facebookresearch.github.io/nougat/), un mod√®le tr√®s efficace de num√©risation de PDF ;
- Le risque de disparition 
d'emplois d'acteurs et sc√©naristes du fait des IA g√©n√©ratrices est l'un des
facteurs √† l'origine de la gr√®ve √† Hollywood ([voir _Le Monde_](https://www.lemonde.fr/economie/article/2023/07/14/greve-a-hollywood-les-acteurs-craignent-d-etre-remplaces-par-des-machines_6181893_3234.html)) ;
- Le mod√®le _open source_ de g√©n√©ration d'images `StableDiffusion` sort une [version XL (`sdxl`)](https://stability.ai/stable-diffusion)  
am√©liorant encore la qualit√© des productions (interface [ici](https://clipdrop.co/fr/stable-diffusion));
- Un [site interactif](https://unehistoireduconflitpolitique.fr/) riche de nombreuses data visualisations est associ√© au nouvel ouvrage de Thomas Piketty et Julia Cag√©, _Une histoire du conflit politique_.

# √âv√©nements

## Masterclass _datascientest_ sur le _fine-tuning_ {#mc-datascientest}

![](../infolettre_11/datascientest.png){width=20% fig-align="center"}


Notre cycle de _masterclass_ organis√©es en lien avec _datascientest_
continue ! 

Apr√®s avoir explor√© en d√©tail les th√©matiques du traitement
automatique du langage et de l'analyse d'image, nous progressons
dans notre parcours avec le sujet du _fine tuning_. 

Au programme: 

- R√©utilisation de _transformers_ (`BERT`) et de LLM (`LLaMA`)
avec les librairies d'`HuggingFace` ;
- _Fine tuning_ de ces mod√®les.

__Rendez-vous le 28 septembre de 10h √† 12h__ !
[Inscription ici](LIEN A CREER)

## Autres √©v√©nements

Quelques √©v√©nements ou informations int√©ressantes :

- [Hackathon velib](https://blog.velib-metropole.fr/hackathon/?utm_source=sendgrid.com&utm_medium=email&utm_campaign=website), fermeture des inscriptions le 29 septembre ;
- [Hackahton de l'ONU](https://unstats.un.org/bigdata/events/2023/un-datathon/): fermeture des inscriptions √† la fin du mois ;
- [Prix du jeune statisticien de l'IAOS](https://mailings.isi-web.org/?na=v&nk=15226-43b0d8c9de&id=563) : article √† envoyer avant le 10 f√©vrier 2024

Les personnes int√©ress√©es par former une √©quipe pour les _hackathons_ peuvent contecter <ssphub-contact@insee.fr>. 