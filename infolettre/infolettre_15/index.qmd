---
title: Infolettre n°15
description: |
  Infolettre de rentrée, __Septembre 2023__

# Date published
date: '2023-09-10'
number: 15

image: learning.png

authors:
  - Lino Galiana

tags:
  - infolettre

categories:
  - Infolettre
---

![](learning.png){width=50% fig-align="center"}

:::{.callout-note}

__*Vous désirez intégrer la liste de diffusion ? L'inscription se fait [ici](https://framaforms.org/integration-reseau-des-data-scientists-1676407156).*__

:::


C'est la rentrée ! Comme les élèves
qui reviennent sur les bancs des écoles,
les modèles de machine learning ont périodiquement
besoin de mettre à jour leurs connaissances
pour dialoguer de manière pertinente. 

Cette _newsletter_ sera donc consacrée aux enjeux
du ré-entrainement et de la spécialisation
de modèles, une question
d'actualité suite à la publication estivale de 
plusieurs grands modèles de langage (LLM) _open source_.


::: {.callout-note}
La première partie de cette _newsletter_
se concentrera sur les
enjeux principaux. La suite sera plus technique 
et évoquera plus en détail certains modèles
ou méthodes de ré-entrainement.  
:::

# Enjeux

Si de nombreuses tâches de modélisation ne nécessitent pas
des modèles trop complexes, deux domaines de
recherche - à savoir le traitement naturel du langage (NLP) et l'analyse d'image -
ont connu ces dernières années des innovations
importantes grâce à des réseaux de neurone à 
l'architecture de plus en plus complexe. 

Pour être en mesure d'entraîner
un modèle complexe, du type LLM, il faut, _a minima_,
disposer des intrants suivants:

- Un __immense volume de données déstructurées__. La constitution de
ces corpus implique le moissonnage en masse
de ressources en ligne, ce qui n'est pas sans poser des
[enjeux juridiques de propriété intellectuelle](https://www.deeplearning.ai/the-batch/time-to-update-copyright-for-generative-ai/) qui ne sont pas encore résolus. 
La récupération de ces données 
nécessite des ressources importantes et une bonne connaissance de la 
structure et la nature des données nécessaires pour entrainer un modèle ;
- Des __ressources informatiques hors du commun__. Les investissements importants
pour les cartes graphiques (GPU), une [ressource en pénurie](https://www.nytimes.com/2023/08/16/technology/ai-gpu-chips-shortage.html) et les
coûts courants associés (électricité, maintenance...) font qu'une poignée d'acteurs du numérique
disposent des ressources adéquates pour entraîner un modèle _ex nihilo_.
Cet article de [Forbes](https://www.forbes.com/sites/craigsmith/2023/09/08/what-large-models-cost-you--there-is-no-free-ai-lunch/) 
évoque des montants qui donnent le tournis. 
- Des __experts__ à l'intersection entre la recherche en mathématique et informatique
ainsi que des compétences en _data engineering_ également en pénurie sur le marché du travail. 

La combinaison de ces facteurs rend difficile si ce n'est impossible
l'entrainement _ex nihilo_ de tels modèles par la majorité
des acteurs de la donnée. Seule une poignée de centres de recherche
diposent de ces ressources pour entraîner _ex nihilo_ ce type de modèles.

Néanmoins, les besoins de ces modèles dépassent le cercle
des acteurs en mesure de les entraîner. 
Plusieurs types de techniques, de [complexité graduelle](https://www.deeplearning.ai/the-batch/tips-for-taking-advantage-of-open-large-language-models/),
ont ainsi émergé pour être en mesure de réutiliser
un modèle pré-entraîné.

Un frein à la réutilisation massive de modèles pré-entraînés est
la nature propriétaire de certains modèles, dont les conditions
de réutilisation peuvent être limitantes. Pour
cette raison, l'émergence de modèles _open source_, dont la
structure est plus transparente (on ne sait, par exemple, pas combien de paramètres
comporte GPT-4) et dont les conditions de réutilisation
sur des infrastructures internes
sont moins restrictives, est devenu ces derniers mois
un enjeu important dans l'écosystème de la donnée. 
Il s'agit d'ailleurs d'un affrontement important entre deux visions
du modèle
économique du secteur numérique : si le co-créateur d'`OpenAI` 
a pu affirmer ["_We were wrong_"](https://www.theverge.com/2023/3/15/23640180/openai-gpt-4-launch-closed-research-ilya-sutskever-interview),
un [mémo interne de Google ayant fuité](https://www.theverge.com/2023/7/10/23790132/google-memo-moat-ai-leak-demis-hassabis)
défendait quant à lui l'idée que les modèles _open source_ sont 
amenés à prendre le dessus, car ils
peuvent bénéficier à plus grande échelle du travail d'experts.

La publication cet été de deux
modèles _open source_ ([`LLaMA-2`](https://ai.meta.com/llama/) et [`Falcon`](https://falconllm.tii.ae/))
ouvre de nouvelles perspectives pour une réutilisation
de modèles dans une infrastructure interne, à condition de
disposer des ressources computationnelles suffisantes
et d'une stratégie adaptée de ré-apprentissage. 

Pour aller plus loin sur ce sujet, la suite de cette _newsletter_
évoque des détails plus techniques. La _masterclass_ sur le
sujet du _fine-tuning_ que nous organisons avec `datascientest`
permettra d'approfondir cette question. 


# Actualités

## De nouveaux grands modèles de langage (LLM)

Pas de vacances pour les principaux acteurs de la _data science_ !
Ce champ de recherche appliquée continue à connaître
une actualité dense avec la publication, cet été, 
de deux modèles importants:

- [`LLaMA-2`](https://ai.meta.com/llama/) par Meta, disponible en versions 7B, 13B et 70B c'est-à-dire, respective, 7, 13 et 70 milliards de paramètres. Dans le domaine des LLM actuels, c'est donc un modèle plutôt minimaliste (`GPT-3` comportait 175 milliards de paramètres, `GPT-4` en comporterait 1.7 trillions soit 1700 milliards) ;
- [`Falcon`](https://falconllm.tii.ae/) par l'Institut d'Innovation et de Technologie d'Abu Dhabi. Alors que [Falcon-40B](https://huggingface.co/tiiuae/falcon-40b) avait déjà connu un engougement important en se plaçant en tête des réutilisations sur HuggingFace, la sortie il y a quelques jours de [Falcon 180B](https://huggingface.co/tiiuae/falcon-180B), dont les performances sont proches de celles des modèles propriétaires. 

Ces deux modèles permettent d'envisager des réutilisations après un ré-entrainement sur des jeux de données _ad hoc_ pour améliorer leurs performances (technique du _fine tuning_). En effet, les grands modèles de langage sont généralement entraînés
sur des corpus génériques de langage naturel principalement issus d'internet (@tbl-corpus-falcon).
Cela les rend capables de comprendre les interactions avec des utilisateurs, notamment leurs instructions (_prompt_)
et d'interagir avec eux de manière assez naturelle. Néanmoins, pour des tâches très spécialisées ou des corpus
particuliers, ces modèles génériques peuvent nécessiter d'être spécialisés pour obtenir de meilleures performances. 

::: {.callout-note collapse="true"}
## Dérouler pour en savoir plus sur le corpus d'entraînement de `Falcon`

: _[Corpus d'entraînement de Falcon 180B](https://huggingface.co/tiiuae/falcon-180B)_{#tbl-corpus-falcon}

  | Source de données | Proportion dans le corpus 
  |-----------|------------|
  | `RefinedWeb-English` (_webscraping_)	| 75%	|
  | `RefinedWeb-Europe`	(_webscraping_) | 7%	|
  | Livres |	6%	|	
  | Sites de conversations (`Reddit`, `StackOverflow`, `HackerNews`...) |	5%	|
  | Code (`Github`...)	| 5% |
  | Documents techniques (`arXiv`, `PubMed`...) |	2%	| 

:::


## Le réentrainement des modèles

[Andrew Ng](https://www.deeplearning.ai/the-batch/tips-for-taking-advantage-of-open-large-language-models/), 
dans sa _newsletter_ estivale,
revient sur les méthodes pour affiner les performances d'un modèle. 

- La technique la plus simple est d'affiner les instructions (_prompt_) fournies à
un modèle. Pour faire l'analogie avec l'apprentissage humain, pour obtenir une réponse
mieux ciblée à une question, il est souvent nécessaire de reformuler une question. 
Par exemple, pour obtenir un code ou 
des explications de meilleurs qualités, il peut être utile de guider un LLM avec des phrases
_"As a data scientist"_ ;
- Fournir quelques exemples à un modèle (_few shot learning_). De même qu'avec les humains, fournir
un petit nombre d'exemples peut suffire, par un raisonnement inductif,
à un modèle à comprendre et réutiliser ce que désire son instructeur. 
Selon la difficulté de la tâche à 
mettre en oeuvre, il peut suffire de très peu de cas pour spécialiser un modèle en modifiant les dernières
couches du réseau de neurone. 
- Réentrainement par spécialisation (_fine tuning_) pour affiner le modèle sur une tâche donnée. 
Il s'agit d'une approche qui peut ressembler à l'apprentissage d'une nouvelle langue pour un humain: 
à partir d'un certain stock de connaissances antérieures (une langue natale), on accumule
des exemples bien choisis en série pour améliorer la compréhension d'une autre langue. 


Cette approche nécessite de disposer de données labellisées, c'est-à-dire de posséder une base de données 
permettant de juger de la qualité des prédictions du modèle. Pour pallier cette absence, il est possible
de mettre en oeuvre un processus humain d'annotation et fournir au modèle ces évaluations pour l'amener
à s'améliorer ([reinformcement learning from human feedback](https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback))

Un réentrainement par spécialisation (_fine tuning_),
qui nécessite des ressources conséquentes mais moindres qu'un entraînement _ex nihilo_,




lien avec masterclass data scientest

Sur l'aspect propriété intellectuelle
https://www.deeplearning.ai/the-batch/time-to-update-copyright-for-generative-ai/


https://www.lebonllm.fr/

What’s new: Researchers at Stanford and UC Berkeley found that the performance of GPT-4 and GPT-3.5 has drifted in recent months. In a limited selection of tasks, some prompts yielded better results than before, some worse.


changement de paradigme dans le développment d'un projet
https://www.deeplearning.ai/the-batch/building-machine-learning-systems-is-more-debugging-than-development/
https://www.deeplearning.ai/the-batch/ai-at-the-speed-of-prompting/


https://www.deeplearning.ai/the-batch/tips-for-taking-advantage-of-open-large-language-models/

